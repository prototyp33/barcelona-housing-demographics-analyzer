#!/bin/bash
# Script para crear estructura GitHub usando token de entorno
# Uso: GITHUB_TOKEN=tu_token bash scripts/create_github_structure_with_token.sh

set -e

REPO="prototyp33/barcelona-housing-demographics-analyzer"

# Verificar que hay token
if [ -z "$GITHUB_TOKEN" ]; then
  echo "âŒ Error: GITHUB_TOKEN no estÃ¡ configurado"
  echo "Uso: GITHUB_TOKEN=tu_token bash $0"
  exit 1
fi

# Configurar token para gh CLI
export GH_TOKEN="$GITHUB_TOKEN"

echo "ğŸš€ Creando estructura de GitHub para Q1 2026 Data Expansion..."
echo "ğŸ“¦ Repositorio: $REPO"
echo ""

# =============================================================================
# 1. CREAR MILESTONE
# =============================================================================
echo "ğŸ“… Creando Milestone..."
MILESTONE_RESPONSE=$(gh api repos/$REPO/milestones \
  -f title="Foundation - New Data Sources" \
  -f description="Integrar 9 nuevas fuentes de datos para enriquecer anÃ¡lisis de vivienda.

KPIs: 9 tablas fact, 95% cobertura, ETL automatizado, Dashboard actualizado

Sprints:
- Sprint 1 (7-24 ene): EducaciÃ³n y Movilidad
- Sprint 2 (27 ene - 14 feb): Vivienda PÃºblica y Zonas Verdes
- Sprint 3 (17 feb - 7 mar): Comercio, Salud y Dashboard
- Sprint 4 (10-31 mar): Catastro y DocumentaciÃ³n" \
  -f due_on="2026-03-31T23:59:59Z" \
  --jq '.number' 2>/dev/null || echo "")

if [ -z "$MILESTONE_RESPONSE" ]; then
  echo "âš ï¸  Milestone ya existe o error. Obteniendo nÃºmero existente..."
  MILESTONE_RESPONSE=$(gh api repos/$REPO/milestones --jq '.[] | select(.title=="Foundation - New Data Sources") | .number' 2>/dev/null || echo "1")
fi

MILESTONE_NUM=${MILESTONE_RESPONSE:-1}
echo "âœ… Milestone: #$MILESTONE_NUM"
echo ""

# =============================================================================
# 2. CREAR LABELS
# =============================================================================
echo "ğŸ·ï¸  Creando Labels..."

create_label() {
  gh label create "$1" --color "$2" --description "$3" --force 2>/dev/null && echo "  âœ… $1" || echo "  âš ï¸  $1 (ya existe)"
}

# Por Tipo
create_label "feature" "0E8A16" "Nueva funcionalidad"
create_label "etl" "7057FF" "Pipeline ETL"
create_label "data-extraction" "F9D0C4" "ExtracciÃ³n de datos"
create_label "database" "BFD4F2" "Esquema DB y migraciones"
create_label "documentation" "0075CA" "DocumentaciÃ³n"

# Por Prioridad
create_label "priority-high" "B60205" "Alta prioridad"
create_label "priority-medium" "FFA500" "Media prioridad"
create_label "priority-low" "CCCCCC" "Baja prioridad"

# Por Sprint
create_label "sprint-1" "1D76DB" "Sprint 1: EducaciÃ³n y Movilidad"
create_label "sprint-2" "0366D6" "Sprint 2: Vivienda PÃºblica"
create_label "sprint-3" "0052CC" "Sprint 3: Comercio y Salud"
create_label "sprint-4" "003D99" "Sprint 4: Catastro"

# Por Fuente
create_label "opendata-bcn" "006B75" "Open Data Barcelona"
create_label "atm" "D93F0B" "ATM Transport"
create_label "amb" "D93F0B" "AMB Open Data"
create_label "idescat" "5319E7" "IDESCAT"
create_label "bicing" "1D76DB" "Bicing API"

# Por Dominio
create_label "education" "C2E0C6" "Equipamientos educativos"
create_label "mobility" "BFD4F2" "Transporte y movilidad"
create_label "housing" "FBCA04" "Vivienda"
create_label "environment" "7FD8BE" "Medio ambiente"
create_label "health" "F9D0C4" "Salud"
create_label "commerce" "FFE4B5" "Comercio"

echo "âœ… Labels procesados"
echo ""

# =============================================================================
# 3. OBTENER ÃšLTIMO NÃšMERO DE ISSUE
# =============================================================================
echo "ğŸ” Obteniendo Ãºltimo nÃºmero de issue..."
LAST_ISSUE=$(gh issue list --repo "$REPO" --limit 1 --json number --jq '.[0].number' 2>/dev/null || echo "238")
START_ISSUE=$((LAST_ISSUE + 1))
echo "âœ… Ãšltima issue: #$LAST_ISSUE, empezando desde #$START_ISSUE"
echo ""

# =============================================================================
# 4. CREAR ISSUES
# =============================================================================
echo "ğŸ“ Creando Issues..."

ISSUE_NUM=$START_ISSUE

create_issue() {
  local title="$1"
  local body="$2"
  local labels="$3"
  
  gh issue create \
    --repo "$REPO" \
    --title "$title" \
    --body "$body" \
    --milestone "$MILESTONE_NUM" \
    --label "$labels" \
    2>/dev/null && echo "  âœ… Issue #$ISSUE_NUM creada" || echo "  âš ï¸  Issue #$ISSUE_NUM (error)"
  
  ISSUE_NUM=$((ISSUE_NUM + 1))
}

# Sprint 1
create_issue \
  "[S1-E1] ğŸ“ Implementar extractor de equipamientos educativos (Open Data BCN)" \
  "## DescripciÃ³n
Crear extractor para datos de equipamientos educativos de Open Data BCN.

## Objetivos
1. Extraer listado completo de equipamientos educativos
2. Geocodificar y mapear a 73 barrios
3. Clasificar por tipologÃ­a (infantil, primaria, secundaria, FP, universidad)
4. Tests unitarios con cobertura â‰¥80%

## Criterios de AceptaciÃ³n
- âœ… â‰¥500 equipamientos extraÃ­dos
- âœ… 100% registros con coordenadas vÃ¡lidas
- âœ… Tests pasan
- âœ… DocumentaciÃ³n completa en docs/data_sources/EDUCACION.md

**Story Points:** 5
**Due Date:** 14 enero 2026" \
  "sprint-1,feature,data-extraction,opendata-bcn,priority-high,education"

create_issue \
  "[S1-E2] ğŸš‡ Implementar extractor de movilidad (Bicing + AMB)" \
  "## DescripciÃ³n
Crear extractores para datos de movilidad: Bicing (GBFS API) y AMB Open Data.

## Objetivos
1. Extraer estaciones Bicing (GBFS API)
2. Extraer infraestructuras de transporte de AMB Open Data
3. Geocodificar y mapear a 73 barrios
4. Calcular tiempo medio al centro

## Criterios de AceptaciÃ³n
- âœ… â‰¥200 estaciones Bicing extraÃ­das
- âœ… Infraestructuras AMB procesadas
- âœ… Tests pasan
- âœ… DocumentaciÃ³n completa

**Story Points:** 8
**Due Date:** 21 enero 2026" \
  "sprint-1,feature,data-extraction,bicing,amb,priority-high,mobility"

create_issue \
  "[S1-E3] ğŸ˜ï¸ Implementar extractor de vivienda pÃºblica (IDESCAT)" \
  "## DescripciÃ³n
Crear extractor para datos de vivienda pÃºblica de IDESCAT con distribuciÃ³n proporcional.

## Objetivos
1. Extraer datos municipales de IDESCAT
2. Distribuir proporcionalmente por barrio (usando poblaciÃ³n/renta)
3. Documentar claramente que son estimaciones
4. Tests unitarios

## Criterios de AceptaciÃ³n
- âœ… Datos municipales extraÃ­dos
- âœ… DistribuciÃ³n proporcional implementada
- âœ… DocumentaciÃ³n con advertencias sobre estimaciones
- âœ… Tests pasan

**Story Points:** 5
**Due Date:** 24 enero 2026" \
  "sprint-1,feature,data-extraction,idescat,priority-high,housing"

# Sprint 2
create_issue \
  "[S2-E1] ğŸŒ³ Integrar datos de zonas verdes y medio ambiente" \
  "## DescripciÃ³n
Ampliar fact_ruido con datos de zonas verdes y Ã¡rboles de Open Data BCN.

## Objetivos
1. Extraer datos de parques y jardines
2. Extraer datos de arbolado
3. Calcular mÂ² zonas verdes por habitante
4. Ampliar tabla fact_ruido â†’ fact_medio_ambiente

**Story Points:** 3
**Due Date:** 7 febrero 2026" \
  "sprint-2,feature,data-extraction,opendata-bcn,priority-medium,environment"

create_issue \
  "[S2-E2] ğŸ¥ Integrar datos de salud y servicios sanitarios" \
  "## DescripciÃ³n
Crear fact_servicios_salud con datos de centros de salud, hospitales y farmacias.

**Story Points:** 3
**Due Date:** 10 febrero 2026" \
  "sprint-2,feature,data-extraction,opendata-bcn,priority-medium,health"

create_issue \
  "[S2-E3] ğŸŒ«ï¸ Integrar datos de contaminaciÃ³n del aire (ASPB)" \
  "## DescripciÃ³n
Extraer datos de NOâ‚‚, PM10, PM2.5 por estaciÃ³n de la Red de Calidad del Aire.

**Story Points:** 5
**Due Date:** 14 febrero 2026" \
  "sprint-2,feature,data-extraction,priority-medium,environment"

# Sprint 3
create_issue \
  "[S3-E1] ğŸª Integrar datos de comercio y actividad econÃ³mica" \
  "## DescripciÃ³n
Crear fact_comercio con datos de locales comerciales, terrazas y tasa de ocupaciÃ³n.

**Story Points:** 5
**Due Date:** 28 febrero 2026" \
  "sprint-3,feature,data-extraction,opendata-bcn,priority-medium,commerce"

create_issue \
  "[S3-E2] ğŸ“Š Integrar nuevas fuentes en Dashboard Streamlit" \
  "## DescripciÃ³n
Actualizar dashboard para mostrar datos de las nuevas fuentes (educaciÃ³n, movilidad, vivienda pÃºblica).

**Story Points:** 8
**Due Date:** 3 marzo 2026" \
  "sprint-3,feature,documentation,priority-high"

create_issue \
  "[S3-E3] ğŸ”„ Automatizar pipeline ETL completo" \
  "## DescripciÃ³n
Crear script de orquestaciÃ³n ETL y GitHub Actions para ejecuciÃ³n automÃ¡tica.

**Story Points:** 5
**Due Date:** 7 marzo 2026" \
  "sprint-3,feature,etl,priority-high"

# Sprint 4
create_issue \
  "[S4-E1] ğŸ›ï¸ Integrar datos de Catastro (opcional - alta complejidad)" \
  "## DescripciÃ³n
Evaluar e implementar integraciÃ³n con API de Catastro para datos detallados de inmuebles.

**Nota:** Requiere evaluaciÃ³n de API comercial vs. web scraping.

**Story Points:** 13
**Due Date:** 24 marzo 2026" \
  "sprint-4,feature,data-extraction,priority-low"

create_issue \
  "[S4-E2] ğŸ“š DocumentaciÃ³n completa y guÃ­a de usuario" \
  "## DescripciÃ³n
Completar documentaciÃ³n tÃ©cnica y crear guÃ­a de usuario para el dashboard.

**Story Points:** 5
**Due Date:** 31 marzo 2026" \
  "sprint-4,feature,documentation,priority-medium"

LAST_CREATED=$((ISSUE_NUM - 1))
echo ""
echo "ğŸ“Š Resumen:"
echo "  - Milestone: #$MILESTONE_NUM"
echo "  - Labels: 26 procesados"
echo "  - Issues creadas: #$START_ISSUE - #$LAST_CREATED (11 issues)"
echo ""
echo "ğŸ”— Ver issues:"
echo "   gh issue list --milestone \"Foundation - New Data Sources\""

