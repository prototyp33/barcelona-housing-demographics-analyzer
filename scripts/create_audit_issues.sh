#!/usr/bin/env bash

set -euo pipefail

# Script para crear GitHub Issues desde el audit de archivos recientes
# Basado en sync_issues.sh del proyecto

current_user="@me"

#
# Issue 1: Bug en regex de _parse_household_size
#
gh issue create \
  --title "ğŸ› Bug en regex de _parse_household_size (utils.py)" \
  --label "bug" \
  --label "etl" \
  --label "data-processing" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

La funciÃ³n `_parse_household_size` en `src/etl/transformations/utils.py` usa un regex con doble backslash (`r"\\d+"`) cuando deberÃ­a usar un solo backslash (`r"\d+"`). En Python raw strings, el doble backslash puede causar que el regex no funcione correctamente.

### ğŸ” Archivos Afectados

- `src/etl/transformations/utils.py:46, 52, 58`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
if normalized.startswith(">"):
    digits = re.findall(r"\\d+", normalized)  # âŒ Doble backslash
```

### âš ï¸ Impacto

- Puede fallar al parsear tamaÃ±os de hogar que contengan nÃºmeros
- Afecta el cÃ¡lculo de mÃ©tricas de hogares en `enrich_fact_demografia`

### âœ… SoluciÃ³n Propuesta

```python
if normalized.startswith(">"):
    digits = re.findall(r"\d+", normalized)  # âœ… Backslash simple
```

### ğŸ“ Pasos para Resolver

- [ ] Corregir regex en lÃ­nea 46
- [ ] Corregir regex en lÃ­nea 52  
- [ ] Corregir regex en lÃ­nea 58
- [ ] AÃ±adir test unitario que verifique parsing de tamaÃ±os de hogar con nÃºmeros

### ğŸ”— Issues Relacionadas

- Relacionada con: cÃ¡lculo de mÃ©tricas demogrÃ¡ficas y enriquecimiento de datos
- Conecta con: Issue #14 "Feature: Completar campos demogrÃ¡ficos faltantes"
'

#
# Issue 2: Manejo de errores genÃ©rico en enrichment.py
#
gh issue create \
  --title "ğŸ”§ Mejorar manejo de errores genÃ©rico en enrichment.py" \
  --label "code-quality" \
  --label "etl" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

MÃºltiples bloques `except Exception` en `src/etl/transformations/enrichment.py` capturan excepciones muy amplias sin especificar tipos concretos, lo que dificulta el debugging y puede ocultar errores inesperados.

### ğŸ” Archivos Afectados

- `src/etl/transformations/enrichment.py:52` (carga de metadatos)
- `src/etl/transformations/enrichment.py:164` (procesamiento de CSV)

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
except Exception as exc:  # noqa: BLE001
    logger.warning("Error cargando metadatos: %s", exc)
```

### âš ï¸ Impacto

- Errores crÃ­ticos pueden ser tratados como warnings
- Dificulta identificar la causa raÃ­z de fallos
- No sigue las mejores prÃ¡cticas del proyecto (ver CODE_AUDIT_ISSUES.md #6)

### âœ… SoluciÃ³n Propuesta

```python
except (FileNotFoundError, pd.errors.ParserError, json.JSONDecodeError) as exc:
    logger.warning("Error cargando metadatos: %s", exc, exc_info=True)
except Exception as exc:
    logger.error("Error inesperado cargando metadatos: %s", exc, exc_info=True)
    raise
```

### ğŸ“ Pasos para Resolver

- [ ] Identificar tipos de excepciones especÃ­ficos para cada bloque try/except
- [ ] Reemplazar `except Exception` por tipos concretos donde sea posible
- [ ] AÃ±adir `exc_info=True` a logs de errores
- [ ] Evaluar si algunos errores deberÃ­an detener el pipeline en lugar de continuar

### ğŸ”— Issues Relacionadas

- Relacionada con: CODE_AUDIT_ISSUES.md #6 (Manejo de Errores GenÃ©rico)
- Conecta con: Issue #43 "Refactor: Limpiar orquestador Pipeline"
'

#
# Issue 3: Import no utilizado en enrichment.py
#
gh issue create \
  --title "ğŸ§¹ Limpiar import no utilizado en enrichment.py" \
  --label "code-quality" \
  --label "cleanup" \
  --label "priority-low" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

El mÃ³dulo `src/etl/transformations/enrichment.py` importa `json` pero estÃ¡ marcado como no utilizado (`# noqa: F401`) con el comentario "se mantiene por compatibilidad si se usa en futuras extensiones". Esto es cÃ³digo muerto que deberÃ­a eliminarse o documentarse mejor.

### ğŸ” Archivos Afectados

- `src/etl/transformations/enrichment.py:38`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
import json  # noqa: F401  # se mantiene por compatibilidad si se usa en futuras extensiones
```

### âš ï¸ Impacto

- CÃ³digo muerto que confunde a linters y desarrolladores
- Import innecesario aumenta tiempo de carga del mÃ³dulo

### âœ… SoluciÃ³n Propuesta

- OpciÃ³n 1: Eliminar el import si realmente no se usa
- OpciÃ³n 2: Si se planea usar en el futuro, moverlo a donde se necesite cuando se implemente

### ğŸ“ Pasos para Resolver

- [ ] Verificar que `json` no se usa en ninguna parte del mÃ³dulo
- [ ] Eliminar el import si no se necesita
- [ ] Si se necesita en el futuro, aÃ±adirlo cuando se implemente la funcionalidad
'

#
# Issue 4: ValidaciÃ³n faltante en prepare_fact_precios
#
gh issue create \
  --title "ğŸ› ValidaciÃ³n faltante en prepare_fact_precios para pipes duplicados" \
  --label "bug" \
  --label "etl" \
  --label "data-quality" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

La funciÃ³n `prepare_fact_precios` detecta pipes duplicados (`|`) en las columnas `source` y `dataset_id` pero solo loguea un error sin corregir el problema. Aunque existe la funciÃ³n `_normalize_pipe_tags` que puede normalizar estos valores, no se aplica automÃ¡ticamente cuando se detecta el problema.

### ğŸ” Archivos Afectados

- `src/etl/transformations/market.py:243-252`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
if fact["source"].astype(str).str.contains(r"\\|").any():
    logger.error(
        "âš ï¸ ALERTA: Se detectaron pipes \"|\" en columna \"source\". "
        "Esto indica un problema de agregaciÃ³n upstream.",
    )
# Solo loguea error, no corrige
```

### âš ï¸ Impacto

- Datos con pipes duplicados pueden persistir en la base de datos
- Puede causar problemas en consultas y anÃ¡lisis posteriores
- La funciÃ³n `_normalize_pipe_tags` ya existe pero no se aplica aquÃ­

### âœ… SoluciÃ³n Propuesta

```python
# Aplicar normalizaciÃ³n automÃ¡ticamente despuÃ©s de detectar el problema
if fact["source"].astype(str).str.contains(r"\\|").any():
    logger.warning(
        "Se detectaron pipes duplicados en \"source\". Normalizando automÃ¡ticamente."
    )
    fact["source"] = fact["source"].apply(_normalize_pipe_tags)
```

### ğŸ“ Pasos para Resolver

- [ ] Aplicar `_normalize_pipe_tags` automÃ¡ticamente cuando se detecten pipes duplicados
- [ ] Cambiar log level de ERROR a WARNING si se corrige automÃ¡ticamente
- [ ] AÃ±adir test que verifique la correcciÃ³n automÃ¡tica de pipes duplicados
- [ ] Documentar el comportamiento en docstring de la funciÃ³n

### ğŸ”— Issues Relacionadas

- Relacionada con: Issue #13 "Fix: DeduplicaciÃ³n agresiva en fact_precios"
- Conecta con: problemas de deduplicaciÃ³n y calidad de datos en fact_precios
'

#
# Issue 5: Tests marcados como skip
#
gh issue create \
  --title "ğŸ§ª Habilitar tests marcados como skip en test_pipeline.py" \
  --label "testing" \
  --label "etl" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

MÃºltiples tests en `tests/test_pipeline.py` estÃ¡n marcados con `@pytest.mark.skip` porque requieren datos con estructura exacta del esquema real. Esto reduce la cobertura de tests y puede ocultar regresiones.

### ğŸ” Archivos Afectados

- `tests/test_pipeline.py:117, 141, 179, 209, 249`

### ğŸ“‹ Tests Afectados

- `test_etl_creates_database` (lÃ­nea 117)
- `test_etl_creates_dim_barrios` (lÃ­nea 141)
- `test_etl_creates_fact_precios` (lÃ­nea 179)
- `test_etl_creates_fact_demografia` (lÃ­nea 209)
- `test_etl_registers_run` (lÃ­nea 249)

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
@pytest.mark.skip(reason="Requiere datos con estructura exacta del esquema real.")
def test_etl_creates_database(raw_data_structure: Dict[str, Path]) -> None:
```

### âš ï¸ Impacto

- Cobertura de tests reducida para el pipeline ETL crÃ­tico
- Regresiones pueden pasar desapercibidas
- Fixtures de prueba no son suficientemente robustos

### âœ… SoluciÃ³n Propuesta

- Crear fixtures mÃ¡s robustos que generen datos con estructura vÃ¡lida
- O documentar claramente cÃ³mo generar datos de prueba vÃ¡lidos
- O crear tests de integraciÃ³n separados que usen datos reales (mÃ¡s lentos pero mÃ¡s completos)

### ğŸ“ Pasos para Resolver

- [ ] Revisar fixtures existentes en `test_pipeline.py`
- [ ] Crear fixtures que generen datos con estructura exacta del esquema
- [ ] Actualizar tests para usar fixtures mejorados
- [ ] Remover `@pytest.mark.skip` cuando los tests pasen
- [ ] Documentar cÃ³mo generar datos de prueba vÃ¡lidos si es necesario

### ğŸ”— Issues Relacionadas

- Relacionada con: Issue #20 "Task: Testing - Unit e Integration Tests"
- Relacionada con: Issue #40 "Tests de integraciÃ³n para pipeline ETL"
- Conecta con: mejoras generales en cobertura de tests del proyecto
'

#
# Issue 6: Manejo de errores silencioso en pipeline.py
#
gh issue create \
  --title "ğŸ”§ Mejorar manejo de errores silencioso en pipeline.py" \
  --label "code-quality" \
  --label "etl" \
  --label "error-handling" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

MÃºltiples bloques `try/except` en `src/etl/pipeline.py` solo loguean warnings pero continÃºan la ejecuciÃ³n del pipeline, incluso cuando algunos errores podrÃ­an ser crÃ­ticos y deberÃ­an detener el proceso.

### ğŸ” Archivos Afectados

- `src/etl/pipeline.py` (mÃºltiples ubicaciones)

### ğŸ“ Ubicaciones ProblemÃ¡ticas

- LÃ­nea 252: Error cargando datos de renta
- LÃ­nea 310: Error procesando demografÃ­a ampliada
- LÃ­nea 363: Error procesando Portal de Dades
- LÃ­nea 394: Error procesando renta
- LÃ­nea 410: Error cargando Idealista venta
- LÃ­nea 421: Error cargando Idealista alquiler
- LÃ­nea 438: Error procesando oferta Idealista

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
try:
    renta_df = _safe_read_csv(renta_path)
    logger.info("âœ“ Datos de renta cargados: %s", renta_path.name)
except Exception as e:
    logger.warning("Error cargando datos de renta: %s", e)
    # ContinÃºa ejecuciÃ³n sin datos de renta
```

### âš ï¸ Impacto

- Errores crÃ­ticos pueden pasar desapercibidos
- Pipeline puede completarse "exitosamente" con datos incompletos
- Dificulta debugging de problemas de datos

### âœ… SoluciÃ³n Propuesta

- Clasificar errores en crÃ­ticos vs. opcionales
- Errores crÃ­ticos (ej: demografÃ­a base) deberÃ­an detener el pipeline
- Errores opcionales (ej: Idealista, Portal de Dades) pueden continuar con warning
- AÃ±adir flag `--strict` para pipeline que falle en cualquier error

### ğŸ“ Pasos para Resolver

- [ ] Clasificar cada fuente de datos como crÃ­tica u opcional
- [ ] Modificar manejo de errores para fuentes crÃ­ticas (raise en lugar de warning)
- [ ] Mantener warnings para fuentes opcionales pero mejorar logging
- [ ] AÃ±adir `exc_info=True` a todos los logs de errores
- [ ] Documentar quÃ© fuentes son crÃ­ticas vs. opcionales

### ğŸ”— Issues Relacionadas

- Relacionada con: Issue #43 "Refactor: Limpiar orquestador Pipeline"
- Conecta con: mejoras generales en robustez y manejo de errores del pipeline ETL
'

#
# Issue 7: Falta validaciÃ³n de aÃ±os en Portal de Dades
#
gh issue create \
  --title "ğŸ› Falta validaciÃ³n de aÃ±os en datos de Portal de Dades" \
  --label "bug" \
  --label "etl" \
  --label "data-quality" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

La funciÃ³n `_extract_year_from_temps` puede retornar `None` cuando falla el parsing de fechas, pero este valor no se valida antes de usarse en agrupaciones y operaciones que requieren aÃ±os vÃ¡lidos.

### ğŸ” Archivos Afectados

- `src/etl/transformations/enrichment.py:112`
- `src/etl/transformations/utils.py:114-120` (funciÃ³n `_extract_year_from_temps`)

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
df["anio"] = df["Dim-00:TEMPS"].apply(_extract_year_from_temps)
df = df.dropna(subset=["anio", "VALUE"])  # âœ… Esto estÃ¡ bien
# Pero en otros lugares puede no validarse:
df.groupby(["anio", ...])  # âŒ Puede fallar si hay None
```

### âš ï¸ Impacto

- Puede causar errores en agrupaciones por aÃ±o si hay valores None
- Datos con fechas invÃ¡lidas pueden ser procesados incorrectamente
- Puede causar errores silenciosos en cÃ¡lculos temporales

### âœ… SoluciÃ³n Propuesta

- Validar que `anio` no sea None antes de agrupar
- AÃ±adir logging cuando se descarten registros por aÃ±o invÃ¡lido
- Documentar comportamiento esperado cuando `_extract_year_from_temps` retorna None

### ğŸ“ Pasos para Resolver

- [ ] Revisar todos los usos de `_extract_year_from_temps`
- [ ] Asegurar que siempre se valida `dropna(subset=["anio"])` antes de agrupar
- [ ] AÃ±adir logging cuando se descarten registros por aÃ±o invÃ¡lido
- [ ] AÃ±adir test que verifique manejo de aÃ±os invÃ¡lidos

### ğŸ”— Issues Relacionadas

- Relacionada con: Issue #15 "Improvement: Mejorar mapeo de territorios Portal de Dades"
- Conecta con: mejoras en procesamiento y validaciÃ³n de datos del Portal de Dades
'

#
# Issue 8: Workflow dashboard-demo sin validaciÃ³n de puerto
#
gh issue create \
  --title "ğŸ”§ AÃ±adir validaciÃ³n de puerto en workflow dashboard-demo" \
  --label "ci-cd" \
  --label "workflow" \
  --label "priority-low" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

El workflow `.github/workflows/dashboard-demo.yml` acepta un puerto como input string pero no valida que estÃ© en un rango vÃ¡lido (1024-65535) antes de usarlo.

### ğŸ” Archivos Afectados

- `.github/workflows/dashboard-demo.yml:10-14, 38`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```yaml
inputs:
  port:
    description: \"Streamlit port (default 8501)\"
    required: false
    default: \"8501\"
    type: string  # âŒ No valida rango
```

### âš ï¸ Impacto

- Puertos invÃ¡lidos pueden causar fallos en el workflow
- Puertos privilegiados (<1024) pueden causar errores de permisos
- Puertos fuera de rango pueden causar errores de conexiÃ³n

### âœ… SoluciÃ³n Propuesta

AÃ±adir step de validaciÃ³n antes de iniciar Streamlit:

```yaml
- name: Validate port
  run: |
    PORT=\"\${{ inputs.port }}\"
    if ! [[ \"\$PORT\" =~ ^[0-9]+\$ ]] || [ \"\$PORT\" -lt 1024 ] || [ \"\$PORT\" -gt 65535 ]; then
      echo \"Error: Port must be between 1024 and 65535\"
      exit 1
    fi
```

### ğŸ“ Pasos para Resolver

- [ ] AÃ±adir step de validaciÃ³n de puerto antes de iniciar Streamlit
- [ ] Validar que el puerto sea numÃ©rico y estÃ© en rango vÃ¡lido
- [ ] AÃ±adir mensaje de error claro si el puerto es invÃ¡lido
- [ ] Documentar rango vÃ¡lido en la descripciÃ³n del input
'

#
# Issue 9: Workflow kpi-update con manejo de errores genÃ©rico
#
gh issue create \
  --title "ğŸ”§ Mejorar manejo de errores en workflow kpi-update" \
  --label "ci-cd" \
  --label "workflow" \
  --label "code-quality" \
  --label "priority-low" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

El workflow `.github/workflows/kpi-update.yml` usa `except:` sin especificar tipo de excepciÃ³n, lo que es una mala prÃ¡ctica y puede ocultar errores inesperados.

### ğŸ” Archivos Afectados

- `.github/workflows/kpi-update.yml:48`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
try:
    with open(\"\$FILE\", \"r\") as f:
        data = json.load(f)
except:  # âŒ Bare except
    data = {\"kpis\": []}
```

### âš ï¸ Impacto

- Puede capturar excepciones crÃ­ticas (KeyboardInterrupt, SystemExit)
- Dificulta debugging de errores reales
- No sigue mejores prÃ¡cticas de Python

### âœ… SoluciÃ³n Propuesta

```python
except (json.JSONDecodeError, FileNotFoundError) as e:
    logger.warning(\"Error cargando KPI progress, inicializando vacÃ­o: %s\", e)
    data = {\"kpis\": []}
```

### ğŸ“ Pasos para Resolver

- [ ] Especificar tipos de excepciones concretos (`json.JSONDecodeError`, `FileNotFoundError`)
- [ ] AÃ±adir logging del error para debugging
- [ ] Evaluar si otros errores deberÃ­an propagarse
'

#
# Issue 10: Falta validaciÃ³n de estructura de manifest.json
#
gh issue create \
  --title "ğŸ› AÃ±adir validaciÃ³n de estructura de manifest.json" \
  --label "bug" \
  --label "etl" \
  --label "data-quality" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

La funciÃ³n `_load_manifest` en `src/etl/pipeline.py` carga el archivo JSON pero no valida que tenga la estructura esperada (lista de diccionarios con campos especÃ­ficos). Esto puede causar fallos silenciosos si el manifest tiene estructura incorrecta.

### ğŸ” Archivos Afectados

- `src/etl/pipeline.py:45-67`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
def _load_manifest(raw_dir: Path) -> List[Dict[str, object]]:
    manifest_path = raw_dir / \"manifest.json\"
    if not manifest_path.exists():
        return []
    
    try:
        with open(manifest_path, \"r\", encoding=\"utf-8\") as f:
            manifest = json.load(f)  # âŒ No valida estructura
        return manifest
```

### âš ï¸ Impacto

- Manifest con estructura incorrecta puede causar errores en tiempo de ejecuciÃ³n
- Errores pueden ser difÃ­ciles de debuggear si el manifest estÃ¡ malformado
- Puede causar fallos silenciosos en descubrimiento de archivos

### âœ… SoluciÃ³n Propuesta

AÃ±adir validaciÃ³n de estructura:

```python
# Validar estructura
if not isinstance(manifest, list):
    logger.error(\"Manifest debe ser una lista, encontrado: %s\", type(manifest))
    return []

# Validar que cada entrada tenga campos mÃ­nimos
required_fields = {\"file_path\", \"type\"}
for i, entry in enumerate(manifest):
    if not isinstance(entry, dict):
        logger.warning(\"Entrada %d del manifest no es un diccionario\", i)
        continue
    missing = required_fields - set(entry.keys())
    if missing:
        logger.warning(\"Entrada %d del manifest falta campos: %s\", i, missing)
```

### ğŸ“ Pasos para Resolver

- [ ] AÃ±adir validaciÃ³n de tipo (debe ser lista)
- [ ] Validar campos requeridos en cada entrada del manifest
- [ ] AÃ±adir logging claro cuando el manifest tiene estructura incorrecta
- [ ] AÃ±adir test que verifique validaciÃ³n de manifest invÃ¡lido
'

#
# Issue 11: FunciÃ³n prepare_idealista_oferta con lÃ³gica incompleta
#
gh issue create \
  --title "ğŸ› LÃ³gica incompleta en prepare_idealista_oferta" \
  --label "bug" \
  --label "etl" \
  --label "code-quality" \
  --label "priority-medium" \
  --assignee "${current_user}" \
  --body '
### ğŸ“Œ DescripciÃ³n

La funciÃ³n `prepare_idealista_oferta` calcula `num_anuncios_tipologia` agrupando por tipologÃ­a pero no incluye este resultado en el DataFrame final. El resultado se asigna a `_` (descartado), lo que es cÃ³digo muerto.

### ğŸ” Archivos Afectados

- `src/etl/transformations/enrichment.py:277-283`

### ğŸ’» CÃ³digo ProblemÃ¡tico

```python
if "tipologia" in df.columns:
    _ = (  # âŒ Resultado descartado
        df.groupby(group_cols + ["tipologia"])
        .size()
        .reset_index(name="num_anuncios_tipologia")
    )

aggregated = df.groupby(group_cols).agg(agg_dict).reset_index()
# num_anuncios_tipologia no se incluye en aggregated
```

### âš ï¸ Impacto

- CÃ³digo muerto que confunde a desarrolladores
- InformaciÃ³n Ãºtil (distribuciÃ³n por tipologÃ­a) se calcula pero no se usa
- Puede indicar funcionalidad incompleta o abandonada

### âœ… SoluciÃ³n Propuesta

- OpciÃ³n 1: Eliminar el cÃ³digo si no se necesita
- OpciÃ³n 2: Incluir `num_anuncios_tipologia` en el resultado agregado si es Ãºtil

### ğŸ“ Pasos para Resolver

- [ ] Evaluar si `num_anuncios_tipologia` es informaciÃ³n Ãºtil para anÃ¡lisis
- [ ] Si es Ãºtil: incluir en el DataFrame agregado (pivot o agregaciÃ³n adicional)
- [ ] Si no es Ãºtil: eliminar el cÃ³digo muerto
- [ ] Documentar decisiÃ³n en comentario o docstring
'

echo "âœ… Todos los issues han sido creados exitosamente"

