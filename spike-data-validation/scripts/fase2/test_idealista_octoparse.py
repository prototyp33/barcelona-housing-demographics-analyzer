#!/usr/bin/env python3
"""
Test del c√≥digo exacto del art√≠culo Octoparse para Idealista.

Basado en: https://www.octoparse.es/blog/como-extraer-los-datos-de-idealista-con-web-scraping

Este script prueba el c√≥digo exacto del art√≠culo para verificar si funciona.
"""

from __future__ import annotations

import requests
from bs4 import BeautifulSoup

# URL de prueba (primero Madrid del art√≠culo, luego Gr√†cia)
url_madrid = 'https://www.idealista.com/en/venta-viviendas/madrid-madrid/'
url_gracia = 'https://www.idealista.com/venta-viviendas/barcelona/gracia/'

# Headers exactos del art√≠culo
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def test_url(url: str, name: str) -> bool:
    """Prueba una URL espec√≠fica."""
    print(f"\n{'='*70}")
    print(f"Probando: {name}")
    print(f"URL: {url}")
    print('='*70)
    
    try:
        # Make the request (c√≥digo exacto del art√≠culo)
        response = requests.get(url, headers=headers, timeout=10)
        
        print(f"Status code: {response.status_code}")
        
        # Check response status
        if response.status_code == 200:
            # Parse the page content
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Find all property listing items (c√≥digo exacto del art√≠culo)
            listings = soup.find_all('article', class_='item')
            
            print(f"Listings encontrados: {len(listings)}")
            
            if len(listings) == 0:
                # Intentar otros selectores alternativos
                print("\nIntentando selectores alternativos...")
                listings_alt1 = soup.find_all('article')
                print(f"  article (sin clase): {len(listings_alt1)}")
                
                listings_alt2 = soup.find_all('div', class_='item')
                print(f"  div.item: {len(listings_alt2)}")
                
                listings_alt3 = soup.find_all('div', {'class': 'item'})
                print(f"  div[class='item']: {len(listings_alt3)}")
                
                # Si encontramos con alternativos, usar esos
                if listings_alt1:
                    listings = listings_alt1[:10]  # Limitar para test
                elif listings_alt2:
                    listings = listings_alt2[:10]
                elif listings_alt3:
                    listings = listings_alt3[:10]
            
            if len(listings) > 0:
                print(f"\n‚úÖ Encontrados {len(listings)} listings")
                print("\nExtrayendo datos de los primeros 3...")
                
                # Extract data for each property (c√≥digo exacto del art√≠culo)
                for i, listing in enumerate(listings[:3], 1):
                    print(f"\n--- Listing {i} ---")
                    
                    # Get the property title
                    title_elem = listing.find('a', class_='item-link')
                    title = title_elem.get_text(strip=True) if title_elem else "N/A"
                    
                    # Get the property price
                    price_elem = listing.find('span', class_='item-price')
                    price = price_elem.get_text(strip=True) if price_elem else "N/A"
                    
                    # Get the property location
                    location_elem = listing.find('span', class_='item-detail')
                    location = location_elem.get_text(strip=True) if location_elem else "N/A"
                    
                    # Print the data
                    print(f'Title: {title}')
                    print(f'Price: {price}')
                    print(f'Location: {location}')
                
                return True
            else:
                print("\n‚ùå No se encontraron listings")
                print("\nInspeccionando estructura HTML...")
                print(f"Tama√±o HTML: {len(response.content)} bytes")
                
                # Buscar elementos comunes
                all_articles = soup.find_all('article')
                all_divs_with_item = soup.find_all('div', class_=lambda x: x and 'item' in x.lower())
                
                print(f"Total <article>: {len(all_articles)}")
                print(f"Total <div> con 'item' en clase: {len(all_divs_with_item)}")
                
                # Guardar HTML para inspecci√≥n
                with open('test_idealista_response.html', 'w', encoding='utf-8') as f:
                    f.write(response.text)
                print("\nüìÑ HTML guardado en: test_idealista_response.html")
                
                return False
        else:
            print(f"‚ùå Error HTTP {response.status_code}")
            if response.status_code == 403:
                print("   Bloqueado por protecci√≥n anti-bot")
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return False

if __name__ == "__main__":
    print("="*70)
    print("TEST C√ìDIGO EXACTO ART√çCULO OCTOPARSE")
    print("="*70)
    
    # Probar primero Madrid (URL del ejemplo del art√≠culo)
    success_madrid = test_url(url_madrid, "Madrid (ejemplo art√≠culo)")
    
    # Probar luego Gr√†cia (nuestro objetivo)
    success_gracia = test_url(url_gracia, "Gr√†cia (nuestro objetivo)")
    
    print("\n" + "="*70)
    print("RESUMEN")
    print("="*70)
    print(f"Madrid: {'‚úÖ OK' if success_madrid else '‚ùå Fall√≥'}")
    print(f"Gr√†cia: {'‚úÖ OK' if success_gracia else '‚ùå Fall√≥'}")
    
    if not success_madrid and not success_gracia:
        print("\n‚ö†Ô∏è  Ambas URLs fallaron. Posibles causas:")
        print("   1. Idealista ha reforzado protecci√≥n desde el art√≠culo")
        print("   2. IP puede estar bloqueada")
        print("   3. Headers necesitan actualizaci√≥n")
        print("   4. Estructura HTML cambi√≥")

