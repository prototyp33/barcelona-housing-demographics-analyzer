# AnÃ¡lisis Modelo Hedonic MICRO v1.0

**Fecha**: 2025-12-19  
**Issue**: #202 - Fase 2  
**Estado**: âš ï¸ Modelo con bajo rendimiento

---

## ðŸ“Š Resultados Modelos Probados

### Modelo 1: Linear Regression

```
RÂ² train:  0.2444
RÂ² test:   0.2055  âŒ (objetivo: â‰¥0.75)
RMSE test: 496.76 â‚¬/mÂ²  âŒ (objetivo: â‰¤250)
Bias test: 75.03 â‚¬/mÂ²  âœ… (objetivo: â‰¤Â±100)
```

**Criterios cumplidos**: 1/5

---

### Modelo 2: Random Forest

```
RÂ² train:  0.8271  (overfitting)
RÂ² test:   -0.1014  âŒâŒ (peor que baseline)
RMSE test: 584.88 â‚¬/mÂ²  âŒ
Bias test: 70.90 â‚¬/mÂ²  âœ…
```

**Criterios cumplidos**: 1/5

---

### Modelo 3: Gradient Boosting

```
RÂ² train:  0.9938  (overfitting extremo)
RÂ² test:   -0.5540  âŒâŒ (muy negativo)
RMSE test: 694.74 â‚¬/mÂ²  âŒ
Bias test: 78.15 â‚¬/mÂ²  âœ…
```

**Criterios cumplidos**: 1/5

---

## ðŸ” DiagnÃ³stico de Problemas

### Problema 1: Correlaciones Muy Bajas

```
Correlaciones con precio_m2:
  superficie_m2:     -0.091  (esperado: +0.3 a +0.5)
  ano_construccion:  +0.212  (esperado: +0.2 a +0.4)
  plantas:          -0.053  (esperado: Â±0.1)
  habitaciones:    -0.223  (esperado: +0.2 a +0.4)
  banos:           -0.181  (esperado: +0.1 a +0.3)
```

**InterpretaciÃ³n**: Las correlaciones son muy bajas o negativas, lo que sugiere:
- âŒ Datos mock pueden tener relaciones artificiales
- âŒ Variables no capturan la variabilidad real del precio
- âŒ Puede haber outliers afectando las correlaciones

---

### Problema 2: Outliers en Superficie

```
Superficie estadÃ­sticas:
  Min:  2.92 mÂ²   âš ï¸ (muy pequeÃ±o, posible error)
  Max: 473.00 mÂ²  âš ï¸ (muy grande, posible error)
  Q1:  69.0 mÂ²
  Q3:  89.0 mÂ²
  IQR: 20.0 mÂ²
```

**Outliers detectados**: ~15% de observaciones fuera de rango normal (20-200 mÂ²)

**Impacto**: Los outliers pueden estar distorsionando el modelo.

---

### Problema 3: TamaÃ±o de Muestra PequeÃ±o

```
Observaciones totales: 100
Train set:             80
Test set:              20  âš ï¸ (muy pequeÃ±o para evaluaciÃ³n confiable)
Features:              11
```

**Ratio observaciones/features**: ~9:1 (recomendado: â‰¥10:1)

**Problema**: Con solo 20 observaciones en test, las mÃ©tricas pueden ser muy volÃ¡tiles.

---

### Problema 4: Overfitting en Modelos No-Lineales

- **Random Forest**: RÂ² train 0.83 vs RÂ² test -0.10 (diferencia enorme)
- **GBM**: RÂ² train 0.99 vs RÂ² test -0.55 (overfitting extremo)

**Causa**: Modelos complejos con pocos datos â†’ memorizan el training set.

---

## ðŸ’¡ Soluciones Propuestas

### SoluciÃ³n 1: Limpiar Outliers (Inmediato)

```python
# Filtrar observaciones con superficie fuera de rango razonable
df_clean = df[(df['superficie_m2'] >= 30) & (df['superficie_m2'] <= 200)].copy()
# Esto deberÃ­a eliminar ~10-15 observaciones extremas
```

**Impacto esperado**: Mejorar correlaciones y estabilidad del modelo.

---

### SoluciÃ³n 2: Usar Log-Transformaciones

```python
# Transformar variables con distribuciÃ³n sesgada
df['log_superficie'] = np.log(df['superficie_m2'])
df['log_precio_m2'] = np.log(df['precio_m2'])
```

**Impacto esperado**: Normalizar distribuciones y mejorar relaciones lineales.

---

### SoluciÃ³n 3: Reducir Features (RegularizaciÃ³n)

```python
# Usar solo features mÃ¡s importantes
features_minimal = ['superficie_m2', 'ano_construccion', 'barrio_id']
# O usar Lasso/Ridge para regularizaciÃ³n automÃ¡tica
```

**Impacto esperado**: Reducir overfitting, mejorar generalizaciÃ³n.

---

### SoluciÃ³n 4: Cross-Validation en vez de Train/Test Split

```python
# Con 100 observaciones, usar 5-fold CV en vez de 80/20 split
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=5, scoring='r2')
```

**Impacto esperado**: EvaluaciÃ³n mÃ¡s robusta con datos limitados.

---

### SoluciÃ³n 5: Usar Datos Reales de Idealista (Cuando Lleguen)

**Problema actual**: Datos mock pueden tener relaciones artificiales.

**SoluciÃ³n**: Cuando lleguen credenciales API, re-entrenar con datos reales.

---

## ðŸŽ¯ RecomendaciÃ³n Inmediata

**Para el spike (validaciÃ³n rÃ¡pida)**:

1. âœ… **Documentar hallazgos** (este documento)
2. âœ… **Limpiar outliers** y re-entrenar
3. âœ… **Probar modelo simplificado** (solo features principales)
4. âœ… **Usar cross-validation** para evaluaciÃ³n mÃ¡s robusta

**Para producciÃ³n**:

1. â³ Esperar datos reales de Idealista API
2. â³ Aumentar tamaÃ±o de muestra (â‰¥200 observaciones)
3. â³ Validar con datos reales

---

## ðŸ“‹ PrÃ³ximos Pasos

1. **Implementar limpieza de outliers** en `train_micro_hedonic.py`
2. **Probar modelo simplificado** (solo superficie, aÃ±o, barrio)
3. **Usar cross-validation** para evaluaciÃ³n
4. **Documentar** que resultados actuales son con datos mock

---

**Ãšltima actualizaciÃ³n**: 2025-12-19

