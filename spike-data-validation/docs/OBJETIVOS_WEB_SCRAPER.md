# Objetivos del Web Scraper - Idealista

**Fecha**: 2025-12-20  
**Proyecto**: Spike de Validaci√≥n - Modelo Hedonic Pricing MICRO  
**Issue**: #202 - Fase 2  
**Script**: `spike-data-validation/scripts/fase2/scrape_idealista_selenium.py`

---

## üéØ Contexto del Proyecto

### **Proyecto General: Barcelona Housing Demographics Analyzer**

Plataforma de an√°lisis que combina datos demogr√°ficos y de mercado inmobiliario para los **73 barrios de Barcelona**, con enfoque especial en el **barrio de Gr√†cia** para validaci√≥n t√©cnica.

### **Spike de Validaci√≥n: Modelo Hedonic Pricing MICRO**

**Objetivo del Spike**: Validar la viabilidad t√©cnica de un modelo hed√≥nico de precios a nivel **micro** (edificio individual) vs. nivel **macro** (agregado por barrio√óa√±o).

**Baseline Actual (MACRO)**:
- R¬≤ = 0.710
- RMSE = 323.47 ‚Ç¨/m¬≤
- Granularidad: `barrio_id √ó anio √ó dataset_id`

**Target (MICRO)**:
- R¬≤ ‚â• 0.75
- RMSE ‚â§ 250 ‚Ç¨/m¬≤
- Sesgo < ¬±100 ‚Ç¨/m¬≤
- Granularidad: **Edificio individual**

---

## üîç Objetivos del Web Scraper

### **Objetivo Principal**

Extraer datos de **precios de mercado** de viviendas en el barrio de **Gr√†cia** desde el portal inmobiliario **Idealista** para alimentar un modelo hed√≥nico de precios a nivel micro (edificio individual).

### **Objetivos Espec√≠ficos**

#### 1. **Obtener Precios de Mercado Actuales**

**Qu√© buscamos**:
- Precios de venta/alquiler de viviendas en Gr√†cia
- Precios por metro cuadrado (`precio_m2`)
- Fechas de publicaci√≥n (para an√°lisis temporal)

**Por qu√© es necesario**:
- Los datos de **Portal Dades** (Issue #199) est√°n agregados por barrio√óa√±o
- Necesitamos precios **individuales por propiedad** para el modelo MICRO
- Idealista es la fuente m√°s completa de precios de mercado en tiempo real

**Resultado esperado**:
- Dataset con precios individuales por propiedad
- M√≠nimo: **50-100 propiedades** para entrenar el modelo
- Ideal: **200-500 propiedades** para mayor robustez

---

#### 2. **Extraer Caracter√≠sticas de las Propiedades**

**Qu√© buscamos**:
- **Superficie** (m¬≤): Variable clave para normalizar precios
- **Habitaciones**: N√∫mero de dormitorios
- **Ba√±os**: N√∫mero de ba√±os
- **Caracter√≠sticas adicionales**: Ascensor, exterior, terraza, etc.
- **Direcci√≥n**: Para matching con datos de Catastro
- **Descripci√≥n**: Texto libre (puede contener informaci√≥n adicional)

**Por qu√© es necesario**:
- Estas caracter√≠sticas son **features** del modelo hed√≥nico
- Permiten explicar la variabilidad de precios entre propiedades similares
- La direcci√≥n permite **matching** con datos de Catastro (Issue #200)

**Resultado esperado**:
- Dataset con caracter√≠sticas estructuradas por propiedad
- Completitud: ‚â•80% en campos cr√≠ticos (precio, superficie, habitaciones)

---

#### 3. **Facilitar Matching con Datos de Catastro**

**Qu√© buscamos**:
- **Direcci√≥n completa**: Calle, n√∫mero, barrio
- **Link del anuncio**: Para validaci√≥n manual si es necesario
- **Coordenadas** (si disponibles): Para matching espacial

**Por qu√© es necesario**:
- Los datos de **Catastro** (Issue #200) tienen caracter√≠sticas f√≠sicas por edificio:
  - Superficie construida
  - A√±o de construcci√≥n
  - N√∫mero de plantas
  - Referencia catastral
- Necesitamos **combinar** precios (Idealista) + caracter√≠sticas f√≠sicas (Catastro) para el modelo MICRO

**Resultado esperado**:
- Dataset con direcciones normalizadas
- Matching rate: ‚â•40% con datos de Catastro (objetivo realista)

---

#### 4. **Validar Pipeline T√©cnico**

**Qu√© buscamos**:
- Validar que el pipeline de extracci√≥n funciona end-to-end
- Identificar problemas t√©cnicos (bloqueos, rate limits, cambios en estructura HTML)
- Documentar limitaciones y alternativas

**Por qu√© es necesario**:
- Este es un **spike de validaci√≥n**, no producci√≥n
- Necesitamos entender si el scraping es viable antes de invertir m√°s tiempo
- Si no es viable, debemos usar la **API oficial de Idealista**

**Resultado esperado**:
- Pipeline funcional o documentaci√≥n clara de por qu√© no es viable
- Decisi√≥n Go/No-Go para usar scraping vs. API

---

## üìä Datos Esperados del Scraper

### **Estructura del Dataset**

| Campo | Tipo | Descripci√≥n | Ejemplo | Prioridad |
|-------|------|-------------|---------|-----------|
| `precio` | `int` | Precio en euros | `950` | üî¥ Cr√≠tico |
| `superficie_m2` | `float` | Superficie en m¬≤ | `45.0` | üî¥ Cr√≠tico |
| `habitaciones` | `int` | N√∫mero de dormitorios | `2` | üü° Importante |
| `banos` | `int` | N√∫mero de ba√±os | `1` | üü° Importante |
| `localidad` | `str` | Direcci√≥n/localidad | `"calle de Antonio L√≥pez, Comillas"` | üî¥ Cr√≠tico |
| `descripcion` | `str` | Descripci√≥n del anuncio | `"Piso REFORMADO..."` | üü¢ Opcional |
| `link` | `str` | URL del anuncio | `"https://www.idealista.com/inmueble/107189787/"` | üü° Importante |
| `detalles` | `str` | Detalles adicionales | `"Bajo interior con ascensor"` | üü¢ Opcional |
| `page` | `int` | N√∫mero de p√°gina | `1` | üü¢ Opcional |

### **Criterios de Calidad**

**Cantidad**:
- **M√≠nimo**: 50 propiedades (para validaci√≥n t√©cnica)
- **Ideal**: 200-500 propiedades (para modelo robusto)
- **√Åmbito geogr√°fico**: Barrio de Gr√†cia (5 barrios: IDs 28-32)

**Calidad**:
- **Completitud**: ‚â•80% en campos cr√≠ticos (`precio`, `superficie_m2`, `localidad`)
- **Validez**: Precios en rango razonable (1,000 - 10,000 ‚Ç¨/m¬≤ para Gr√†cia)
- **Unicidad**: Sin duplicados (mismo `link`)

**Temporalidad**:
- **Per√≠odo**: Anuncios recientes (√∫ltimos 3-6 meses)
- **Actualizaci√≥n**: Datos de mercado actual (no hist√≥ricos agregados)

---

## üîÑ Integraci√≥n en el Pipeline

### **Flujo Completo del Pipeline MICRO**

```
1. Catastro (Issue #200)
   ‚îî‚îÄ> Caracter√≠sticas f√≠sicas por edificio
       (superficie, a√±o, plantas, referencia catastral)

2. Idealista (Web Scraper - Este documento)
   ‚îî‚îÄ> Precios de mercado por propiedad
       (precio, superficie, habitaciones, direcci√≥n)

3. Matching (Issue #201)
   ‚îî‚îÄ> Combinar Catastro + Idealista
       (matching por referencia catastral o direcci√≥n fuzzy)

4. Modelo Hedonic (Issue #202)
   ‚îî‚îÄ> Entrenar modelo MICRO
       (precio_m2 ~ caracter√≠sticas f√≠sicas + caracter√≠sticas de mercado)
```

### **Rol del Web Scraper en el Pipeline**

**Input**:
- URL base de Idealista para Gr√†cia
- Filtros: Venta/Alquiler, barrio, precio, etc.

**Proceso**:
1. Navegar a p√°ginas de resultados de Idealista
2. Extraer datos de cada propiedad (precio, caracter√≠sticas, direcci√≥n)
3. Manejar paginaci√≥n (m√∫ltiples p√°ginas)
4. Guardar datos en CSV estructurado

**Output**:
- CSV: `spike-data-validation/data/processed/fase2/idealista_gracia_selenium.csv`
- Formato: Compatible con `match_catastro_idealista.py`

**Siguiente paso**:
- El script `match_catastro_idealista.py` combina:
  - Datos de Catastro (caracter√≠sticas f√≠sicas)
  - Datos de Idealista (precios de mercado)
  - Matching por referencia catastral o direcci√≥n

---

## üìà Resultado Esperado

### **Dataset Final para Modelo MICRO**

**Archivo**: `spike-data-validation/data/processed/fase2/idealista_catastro_matched.csv`

**Estructura esperada**:

| Campo | Fuente | Descripci√≥n |
|-------|--------|-------------|
| `referencia_catastral` | Catastro | ID √∫nico del edificio |
| `precio` | Idealista | Precio de la propiedad |
| `precio_m2` | Calculado | `precio / superficie_m2` |
| `superficie_m2` | Catastro/Idealista | Superficie (preferir Catastro) |
| `ano_construccion` | Catastro | A√±o de construcci√≥n |
| `plantas` | Catastro | N√∫mero de plantas del edificio |
| `habitaciones` | Idealista | N√∫mero de dormitorios |
| `banos` | Idealista | N√∫mero de ba√±os |
| `ascensor` | Idealista | Boolean (tiene ascensor) |
| `exterior` | Idealista | Boolean (vista exterior) |
| `barrio_id` | Calculado | ID del barrio (28-32 para Gr√†cia) |
| `direccion` | Idealista/Catastro | Direcci√≥n normalizada |

**M√©tricas esperadas**:
- **Observaciones**: 50-200 propiedades matched
- **Matching rate**: ‚â•40% (realista con datos reales)
- **Completitud**: ‚â•80% en campos cr√≠ticos
- **Cobertura temporal**: √öltimos 3-6 meses

---

## üéØ M√©tricas de √âxito del Scraper

### **M√©tricas T√©cnicas**

| M√©trica | Objetivo | Estado Actual |
|---------|----------|---------------|
| **Propiedades extra√≠das** | ‚â•50 | ‚ö†Ô∏è Bloqueado por IP |
| **Tasa de √©xito** | ‚â•80% p√°ginas | ‚ùå 0% (bloqueo) |
| **Completitud datos** | ‚â•80% campos cr√≠ticos | N/A (sin datos) |
| **Tiempo de ejecuci√≥n** | ‚â§30 min (10 p√°ginas) | N/A |

### **M√©tricas de Calidad**

| M√©trica | Objetivo | Validaci√≥n |
|---------|----------|------------|
| **Precios v√°lidos** | 100% en rango razonable | Validar con estad√≠sticas |
| **Direcciones parseables** | ‚â•90% | Validar con matching |
| **Sin duplicados** | 0% | Validar por `link` √∫nico |

### **Criterio Go/No-Go**

**‚úÖ GO (Scraping viable)**:
- Se extraen ‚â•50 propiedades
- Tasa de √©xito ‚â•80%
- Datos de calidad suficiente para matching

**‚ùå NO-GO (Usar API)**:
- Bloqueo sistem√°tico (IP, CAPTCHA)
- Tasa de √©xito <50%
- Datos insuficientes o de baja calidad

**Estado actual**: ‚ùå **NO-GO** (bloqueo de IP confirmado)

**Alternativa**: Usar **API oficial de Idealista** (ver `IDEALISTA_API_SETUP.md`)

---

## üîó Integraci√≥n con Otros Componentes

### **Scripts Relacionados**

1. **`scrape_idealista_selenium.py`** (Este scraper)
   - Extrae datos de Idealista
   - Output: `idealista_gracia_selenium.csv`

2. **`match_catastro_idealista.py`**
   - Combina Catastro + Idealista
   - Matching por referencia catastral o direcci√≥n
   - Output: `idealista_catastro_matched.csv`

3. **`train_micro_hedonic.py`**
   - Entrena modelo hed√≥nico MICRO
   - Input: `idealista_catastro_matched.csv`
   - Output: Modelo entrenado + m√©tricas

### **Dependencias**

**Input requerido**:
- ‚úÖ Datos de Catastro (Issue #200): `catastro_gracia_real.csv`
- ‚è≥ Datos de Idealista (este scraper): `idealista_gracia_selenium.csv`

**Output generado**:
- Dataset matched: `idealista_catastro_matched.csv`
- Modelo entrenado: `micro_hedonic_model.pkl`
- M√©tricas: `micro_hedonic_metrics.json`

---

## üìù Limitaciones Conocidas

### **Limitaciones T√©cnicas**

1. **Bloqueo de IP**:
   - Idealista detecta y bloquea scraping automatizado
   - Soluci√≥n: VPN o API oficial

2. **CAPTCHA**:
   - Idealista muestra CAPTCHA para prevenir scraping
   - Soluci√≥n: Resoluci√≥n manual (modo visible) o API oficial

3. **Rate Limiting**:
   - Idealista puede limitar requests por IP
   - Soluci√≥n: Delays entre requests (2-20 segundos)

4. **Cambios en Estructura HTML**:
   - Idealista puede cambiar estructura HTML
   - Soluci√≥n: Selectores CSS robustos + actualizaci√≥n peri√≥dica

### **Limitaciones de Datos**

1. **Cobertura geogr√°fica**:
   - Solo barrio de Gr√†cia (5 barrios)
   - No todos los barrios de Barcelona

2. **Cobertura temporal**:
   - Solo anuncios actuales (√∫ltimos 3-6 meses)
   - No datos hist√≥ricos completos

3. **Matching rate**:
   - Matching con Catastro puede ser <50%
   - Depende de calidad de direcciones

---

## üéØ Conclusi√≥n

### **Objetivo Principal del Scraper**

Extraer **precios de mercado individuales** de Idealista para el barrio de Gr√†cia, que se combinar√°n con **caracter√≠sticas f√≠sicas de Catastro** para entrenar un **modelo hed√≥nico de precios a nivel micro** (edificio individual).

### **Estado Actual**

**Scraping**: ‚ùå **No viable** (bloqueo de IP confirmado)

**Alternativa recomendada**: ‚úÖ **API oficial de Idealista**
- Registro: https://developers.idealista.com/
- L√≠mite: 150 calls/mes
- Estable y legal

### **Pr√≥ximos Pasos**

1. **Si se obtienen credenciales API**:
   - Usar `extract_idealista_api_gracia.py`
   - Extraer datos reales
   - Continuar con matching y modelo

2. **Si no se obtienen credenciales API**:
   - Continuar con datos mock para validaci√≥n t√©cnica del pipeline
   - Documentar limitaciones
   - Decisi√≥n Go/No-Go basada en pipeline t√©cnico

---

## üìö Referencias

- **Gu√≠a de uso scraper**: `GUIA_USO_SELENIUM.md`
- **Soluciones bloqueo IP**: `BLOQUEO_IP_SOLUCIONES.md`
- **Setup API Idealista**: `IDEALISTA_API_SETUP.md`
- **Plan Fase 2**: `ISSUE_202_FASE2_PLAN.md`
- **Resumen Fase 2**: `FASE2_SUMMARY.md`

---

**√öltima actualizaci√≥n**: 2025-12-20  
**Mantenido por**: Equipo A - Data Infrastructure

