# Code Audit - Issues Found

**Fecha:** 2025-12-01  
**Auditor:** AI Assistant  
**Alcance:** C√≥digo fuente completo (`src/`, `scripts/`, `tests/`)

---

## Resumen Ejecutivo

Se encontraron **47 issues** categorizados en:
- üî¥ **Cr√≠ticos:** 8
- üü° **Importantes:** 15
- üü¢ **Mejoras:** 24

---

## üî¥ Issues Cr√≠ticos (Alta Prioridad)

### 1. C√≥digo Duplicado: `data_extraction.py` vs `extraction/`
**Archivo:** `src/data_extraction.py`  
**Severidad:** Cr√≠tica  
**Descripci√≥n:**  
Existe un m√≥dulo legacy `data_extraction.py` (2547 l√≠neas) que duplica funcionalidad de los extractores modulares en `src/extraction/`. Esto genera:
- Confusi√≥n sobre qu√© c√≥digo usar
- Mantenimiento duplicado
- Riesgo de inconsistencias

**Impacto:**
- Duplicaci√≥n de ~2000 l√≠neas de c√≥digo
- Clases duplicadas: `OpenDataBCNExtractor`, `IdealistaExtractor`, `PortalDadesExtractor`
- Dos sistemas de logging diferentes

**Recomendaci√≥n:**
- [ ] Auditar qu√© c√≥digo legacy a√∫n se usa
- [ ] Migrar referencias restantes a `extraction/`
- [ ] Eliminar `data_extraction.py` o marcarlo como deprecated

---

### 2. SQL Injection Potencial en `data_loader.py`
**Archivo:** `src/app/data_loader.py:80`  
**Severidad:** Cr√≠tica  
**C√≥digo:**
```python
df = pd.read_sql(f"SELECT MIN(anio) as min_year, MAX(anio) as max_year FROM {table}", conn)
```

**Problema:**  
Uso de f-string con nombre de tabla sin validaci√≥n. Aunque `table` viene de una lista controlada, es una mala pr√°ctica.

**Recomendaci√≥n:**
```python
# Validar tabla contra lista blanca
ALLOWED_TABLES = ["fact_precios", "fact_demografia", "fact_renta"]
if table not in ALLOWED_TABLES:
    raise ValueError(f"Tabla no permitida: {table}")
df = pd.read_sql(f"SELECT MIN(anio) as min_year, MAX(anio) as max_year FROM {table}", conn)
```

---

### 3. SQL Injection Potencial en `database_setup.py`
**Archivo:** `src/database_setup.py:214`  
**Severidad:** Cr√≠tica  
**C√≥digo:**
```python
conn.execute(f"DELETE FROM {table};")
```

**Problema:**  
Similar al anterior, aunque `table` viene de una lista controlada en `truncate_tables()`.

**Recomendaci√≥n:**
```python
ALLOWED_TABLES = {"dim_barrios", "fact_precios", "fact_demografia", ...}
if table not in ALLOWED_TABLES:
    raise ValueError(f"Tabla no permitida para truncado: {table}")
conn.execute(f"DELETE FROM {table};")
```

---

### 4. `IncasolSocrataExtractor` No Registrado en `__init__.py`
**Archivo:** `src/extraction/__init__.py`  
**Severidad:** Cr√≠tica  
**Descripci√≥n:**  
La clase `IncasolSocrataExtractor` existe en `src/extraction/incasol.py` pero no est√° exportada en `__init__.py`, por lo que no es importable desde `src.extraction`.

**Recomendaci√≥n:**
```python
from .incasol import IncasolSocrataExtractor
__all__ = [
    # ... existing exports ...
    "IncasolSocrataExtractor",
]
```

---

### 5. Uso de `print()` en lugar de Logger
**Archivo:** `src/data_extraction.py:40`  
**Severidad:** Cr√≠tica  
**C√≥digo:**
```python
print("WARNING: Playwright no est√° instalado...", file=sys.stderr)
```

**Problema:**  
Deber√≠a usar el sistema de logging establecido.

**Recomendaci√≥n:**
```python
logger.warning("Playwright no est√° instalado. El extractor PortalDades requerir√°: pip install playwright && playwright install")
```

---

### 6. Manejo de Errores Gen√©rico en `data_processing.py`
**Archivo:** `src/data_processing.py` (m√∫ltiples lugares)  
**Severidad:** Cr√≠tica  
**Ejemplos:**
- L√≠nea 559: `except (UnicodeDecodeError, pd.errors.ParserError):` - OK
- Pero hay lugares donde se capturan excepciones muy amplias sin contexto suficiente

**Recomendaci√≥n:**
- Revisar todos los `except Exception` y especificar tipos concretos
- A√±adir logging con `exc_info=True` en todos los casos

---

### 7. Hardcoding de A√±o 2022 en M√∫ltiples Lugares
**Archivo:** `src/app/data_loader.py` (m√∫ltiples funciones)  
**Severidad:** Cr√≠tica  
**Ejemplos:**
- `load_renta(year: int = 2022)` - hardcodea 2022 como default
- `load_affordability_data()` - hardcodea `WHERE anio = 2022` en l√≠nea 247
- `load_temporal_comparison()` - hardcodea `WHERE anio = 2022` en l√≠nea 291

**Problema:**  
Los datos de renta ahora est√°n disponibles para 2015-2023, pero el c√≥digo sigue asumiendo solo 2022.

**Recomendaci√≥n:**
- Actualizar funciones para usar el a√±o pasado como par√°metro
- Actualizar documentaci√≥n y UI para reflejar a√±os disponibles

---

### 8. Falta Validaci√≥n de Integridad Referencial en ETL
**Archivo:** `src/etl/pipeline.py`  
**Severidad:** Cr√≠tica  
**Descripci√≥n:**  
El ETL carga datos en tablas con foreign keys pero no valida expl√≠citamente que todos los `barrio_id` en fact tables existan en `dim_barrios` antes de insertar.

**Recomendaci√≥n:**
```python
# Antes de cargar fact tables, validar:
invalid_barrios = fact_precios[~fact_precios['barrio_id'].isin(dim_barrios['barrio_id'])]
if not invalid_barrios.empty:
    logger.error(f"Barrios inv√°lidos encontrados: {invalid_barrios['barrio_id'].unique()}")
    raise ValueError("Integridad referencial violada")
```

---

## üü° Issues Importantes (Media Prioridad)

### 9. Falta Type Hints Completos
**Archivos:** M√∫ltiples  
**Severidad:** Importante  
**Ejemplos:**
- `src/data_processing.py`: Muchas funciones tienen type hints parciales
- `src/app/data_loader.py`: Algunas funciones retornan `dict` sin especificar estructura

**Recomendaci√≥n:**
- Usar `TypedDict` para estructuras de diccionarios complejas
- Completar type hints en todas las funciones p√∫blicas

---

### 10. Manejo Inconsistente de Valores Nulos
**Archivo:** `src/data_processing.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
Hay m√∫ltiples estrategias para manejar nulos:
- Algunos lugares usan `pd.NA`
- Otros usan `np.nan`
- Otros usan `None`
- Algunos usan `.fillna()`, otros `.dropna()`

**Recomendaci√≥n:**
- Estandarizar: usar `pd.NA` para DataFrames, `None` para Python nativo
- Documentar estrategia de manejo de nulos por tipo de dato

---

### 11. Falta Validaci√≥n de Esquema en `prepare_renta_barrio`
**Archivo:** `src/data_processing.py:1786`  
**Severidad:** Importante  
**Descripci√≥n:**  
La funci√≥n busca columnas de renta con nombres espec√≠ficos pero no valida que los valores sean razonables (ej: renta negativa, valores extremos).

**Recomendaci√≥n:**
```python
# Validar rangos razonables
if (df[renta_col] < 0).any():
    logger.warning("Se encontraron valores de renta negativos")
if (df[renta_col] > 200000).any():
    logger.warning("Se encontraron valores de renta extremadamente altos (>200k‚Ç¨)")
```

---

### 12. Cache TTL Hardcodeado en `data_loader.py`
**Archivo:** `src/app/data_loader.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
Todos los `@st.cache_data` usan `ttl=3600` (1 hora) hardcodeado. Deber√≠a ser configurable.

**Recomendaci√≥n:**
```python
from src.app.config import CACHE_TTL
@st.cache_data(ttl=CACHE_TTL)
```

---

### 13. Falta Manejo de Conexiones SQLite en Context Managers
**Archivo:** `src/app/data_loader.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
Las conexiones SQLite se abren y cierran manualmente con `try/finally`, pero no usan context managers.

**Recomendaci√≥n:**
```python
from contextlib import contextmanager

@contextmanager
def get_db_connection():
    conn = get_connection()
    try:
        yield conn
    finally:
        conn.close()

# Uso:
with get_db_connection() as conn:
    df = pd.read_sql(query, conn)
```

---

### 14. F-Strings en SQL Queries (Aunque con Par√°metros)
**Archivo:** `src/app/data_loader.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
Aunque se usan par√°metros para valores (`params=[year]`), se usan f-strings para construir queries complejas. Esto es aceptable pero podr√≠a mejorarse.

**Ejemplo:**
```python
f"""
SELECT ...
(p.avg_precio_m2 * {VIVIENDA_TIPO_M2}) / r.renta_euros AS effort_ratio
"""
```

**Recomendaci√≥n:**
- Mover constantes como `VIVIENDA_TIPO_M2` a par√°metros de query si es posible
- O documentar que estas son constantes de configuraci√≥n, no datos de usuario

---

### 15. Falta Validaci√≥n de A√±os Disponibles en UI
**Archivo:** `src/app/main.py:75-88`  
**Severidad:** Importante  
**Descripci√≥n:**  
El sidebar hardcodea que renta solo est√° disponible para 2022, pero ahora hay datos 2015-2023.

**C√≥digo actual:**
```python
if selected_metric == "Renta Mensual":
    st.info("Mostrando datos disponibles para **2022** (√önico registro oficial de renta)")
    selected_year = 2022
    disable_slider = True
```

**Recomendaci√≥n:**
- Consultar a√±os disponibles din√°micamente desde `load_available_years()`
- Habilitar slider si hay m√∫ltiples a√±os disponibles

---

### 16. Falta Manejo de Errores en `build_geojson`
**Archivo:** `src/app/data_loader.py:446`  
**Severidad:** Importante  
**Descripci√≥n:**  
La funci√≥n `build_geojson` hace `json.loads()` sin manejo de errores si el JSON es inv√°lido.

**Recomendaci√≥n:**
```python
try:
    geometry = json.loads(row["geometry_json"])
except (json.JSONDecodeError, TypeError) as e:
    logger.warning(f"GeoJSON inv√°lido para barrio {row['barrio_id']}: {e}")
    continue
```

---

### 17. Falta Validaci√≥n de DataFrame Vac√≠o en M√∫ltiples Funciones
**Archivo:** `src/data_processing.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
Muchas funciones asumen que el DataFrame tiene datos, pero no validan expl√≠citamente al inicio.

**Recomendaci√≥n:**
- A√±adir validaci√≥n temprana: `if df.empty: return pd.DataFrame()` o `raise ValueError`
- Documentar comportamiento cuando DataFrame est√° vac√≠o

---

### 18. Magic Numbers en C√°lculos
**Archivo:** `src/data_processing.py`, `src/app/data_loader.py`  
**Severidad:** Importante  
**Ejemplos:**
- `VIVIENDA_TIPO_M2 = 70` est√° bien definido en config
- Pero hay otros n√∫meros m√°gicos: `* 100` para porcentajes, `* 12` para anualizar alquiler

**Recomendaci√≥n:**
- Extraer a constantes con nombres descriptivos
- O documentar en comentarios inline

---

### 19. Falta Logging de M√©tricas de Calidad de Datos
**Archivo:** `src/data_processing.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
El ETL no registra m√©tricas de calidad como:
- Porcentaje de valores nulos por columna
- N√∫mero de registros descartados por validaci√≥n
- Distribuci√≥n de valores (min, max, media) para detectar outliers

**Recomendaci√≥n:**
- A√±adir funci√≥n `log_data_quality_metrics(df, table_name)` que se ejecute antes de cargar en SQLite

---

### 20. Inconsistencia en Nombres de Columnas de Renta
**Archivo:** `src/data_processing.py:1822`  
**Severidad:** Importante  
**Descripci√≥n:**  
La funci√≥n busca columnas con nombres variados: `["Import_Euros", "Import_Renda_Bruta_‚Ç¨", "Import"]`. Esto es fr√°gil.

**Recomendaci√≥n:**
- Documentar nombres esperados por fuente
- A√±adir mapeo expl√≠cito por `source` o `dataset_id`

---

### 21. Falta Validaci√≥n de Rangos Temporales
**Archivo:** `src/etl/pipeline.py`  
**Severidad:** Importante  
**Descripci√≥n:**  
El ETL no valida que los a√±os en los datos est√©n dentro de rangos esperados (ej: no hay a√±os futuros, no hay a√±os antes de 2010).

**Recomendaci√≥n:**
```python
MIN_VALID_YEAR = 2010
MAX_VALID_YEAR = datetime.now().year + 1
if (df['anio'] < MIN_VALID_YEAR).any() or (df['anio'] > MAX_VALID_YEAR).any():
    logger.warning(f"A√±os fuera de rango v√°lido detectados")
```

---

### 22. Falta Documentaci√≥n de Estrategias de Deduplicaci√≥n
**Archivo:** `src/data_processing.py:462-497`  
**Severidad:** Importante  
**Descripci√≥n:**  
La l√≥gica de deduplicaci√≥n es compleja y est√° bien comentada, pero falta documentaci√≥n de alto nivel sobre cu√°ndo se aplica cada estrategia.

**Recomendaci√≥n:**
- Crear documento `docs/ETL_DEDUPLICATION_STRATEGY.md` explicando la pol√≠tica

---

### 23. Falta Manejo de Encoding en `_load_portaldades_csv`
**Archivo:** `src/data_processing.py:539`  
**Severidad:** Importante  
**Descripci√≥n:**  
La funci√≥n maneja encoding bien, pero si `chardet` falla, hace fallback silencioso a UTF-8 que puede fallar.

**Recomendaci√≥n:**
- A√±adir logging cuando se usa fallback
- Considerar lanzar excepci√≥n si todos los encodings fallan (ya lo hace, pero el mensaje podr√≠a ser m√°s claro)

---

## üü¢ Mejoras y Optimizaciones (Baja Prioridad)

### 24. Optimizaci√≥n de Queries SQL
**Archivo:** `src/app/data_loader.py`  
**Severidad:** Baja  
**Descripci√≥n:**  
Algunas queries hacen m√∫ltiples subconsultas que podr√≠an optimizarse con JOINs m√°s eficientes o √≠ndices.

**Ejemplo:** `load_affordability_data()` tiene m√∫ltiples subconsultas que podr√≠an combinarse.

---

### 25. Falta Tests para Funciones de `data_processing.py`
**Archivo:** `tests/`  
**Severidad:** Baja  
**Descripci√≥n:**  
Hay tests para extractores pero pocos para funciones de transformaci√≥n/limpieza en `data_processing.py`.

**Recomendaci√≥n:**
- Crear `tests/test_data_processing.py` con tests para funciones clave

---

### 26. Falta Validaci√≥n de Tipos en Runtime
**Archivo:** M√∫ltiples  
**Severidad:** Baja  
**Descripci√≥n:**  
Aunque hay type hints, no hay validaci√≥n en runtime (ej: con `pydantic` o `typeguard`).

---

### 27. Falta Configuraci√≥n Centralizada para Thresholds
**Archivo:** M√∫ltiples  
**Severidad:** Baja  
**Descripci√≥n:**  
Thresholds como `MIN_RECORDS_WARNING = 10` est√°n hardcodeados en diferentes m√≥dulos.

**Recomendaci√≥n:**
- Mover a `src/app/config.py` o crear `src/config.py` centralizado

---

### 28. Falta Documentaci√≥n de API de Funciones P√∫blicas
**Archivo:** M√∫ltiples  
**Severidad:** Baja  
**Descripci√≥n:**  
Algunas funciones p√∫blicas tienen docstrings incompletos o faltan ejemplos de uso.

---

### 29. Falta Manejo de Versiones de Datasets
**Archivo:** `src/etl/pipeline.py`  
**Severidad:** Baja  
**Descripci√≥n:**  
No hay tracking de versiones de datasets procesados (solo timestamps).

**Recomendaci√≥n:**
- A√±adir campo `dataset_version` en `etl_runs` o crear tabla `dataset_versions`

---

### 30. Falta Validaci√≥n de Coherencia Temporal
**Archivo:** `src/data_processing.py`  
**Severidad:** Baja  
**Descripci√≥n:**  
No se valida que las fechas en los datos sean coherentes (ej: `etl_loaded_at` no puede ser futuro).

---

### 31-47. Issues Menores

- **31.** Falta `__repr__` en algunas clases de extractores
- **32.** Algunos imports no utilizados (detectables con `flake8 --select=F401`)
- **33.** L√≠neas muy largas (>100 caracteres) en algunos lugares
- **34.** Falta `__all__` en algunos m√≥dulos
- **35.** Algunos comentarios en espa√±ol, otros en ingl√©s (inconsistencia)
- **36.** Falta `.gitignore` para archivos temporales de tests
- **37.** Falta validaci√≥n de que `dim_barrios` tiene exactamente 73 barrios
- **38.** Falta logging de tiempo de ejecuci√≥n de funciones cr√≠ticas
- **39.** Algunas funciones muy largas (>100 l√≠neas) podr√≠an dividirse
- **40.** Falta manejo de timeouts en algunas requests HTTP
- **41.** Falta retry logic en algunas operaciones de red
- **42.** Falta validaci√≥n de tama√±o de archivos antes de cargar
- **43.** Falta compresi√≥n de archivos raw grandes
- **44.** Falta validaci√≥n de checksums de archivos descargados
- **45.** Falta documentaci√≥n de rate limits por fuente
- **46.** Falta manejo de cuotas de API (ej: Idealista 150 calls/month)
- **47.** Falta alertas cuando datos est√°n desactualizados (>6 meses sin actualizar)

---

## Priorizaci√≥n Recomendada

### Sprint Inmediato (Esta Semana)
1. ‚úÖ Registrar `IncasolSocrataExtractor` en `__init__.py` (#4)
2. ‚úÖ Actualizar hardcoding de a√±o 2022 para renta (#7)
3. ‚úÖ A√±adir validaci√≥n SQL injection en `data_loader.py` (#2)
4. ‚úÖ Reemplazar `print()` por logger (#5)

### Sprint Pr√≥ximo (Pr√≥ximas 2 Semanas)
5. ‚úÖ Auditar y eliminar c√≥digo duplicado `data_extraction.py` (#1)
6. ‚úÖ A√±adir validaci√≥n de integridad referencial (#8)
7. ‚úÖ Mejorar manejo de errores gen√©ricos (#6)
8. ‚úÖ Actualizar UI para a√±os disponibles din√°micamente (#15)

### Backlog (Pr√≥ximo Mes)
9-23. Issues importantes de media prioridad
24-47. Mejoras y optimizaciones

---

## M√©tricas de Calidad

- **Cobertura de Tests:** ~60% (estimado)
- **Type Hints:** ~80% completo
- **Documentaci√≥n:** ~70% completo
- **Linting:** ‚úÖ Sin errores
- **Duplicaci√≥n de C√≥digo:** üî¥ Alta (2000+ l√≠neas duplicadas)
- **Complejidad Ciclom√°tica:** üü° Media-Alta en algunas funciones

---

## Conclusi√≥n

El c√≥digo est√° en buen estado general, pero hay **8 issues cr√≠ticos** que deber√≠an abordarse antes de nuevas features. La mayor√≠a son problemas de mantenibilidad y robustez m√°s que bugs funcionales.

**Recomendaci√≥n:** Priorizar issues #1, #2, #4, #7 esta semana para estabilizar la base antes de continuar con nuevas funcionalidades.

