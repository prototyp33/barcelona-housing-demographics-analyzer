# AutomatizaciÃ³n de Carga del Master Table en Pipeline ETL

**Fecha**: 2025-12-14  
**Estado**: âœ… Implementado

---

## ğŸ“‹ Resumen

La carga del Master Table (`fact_housing_master`) ahora estÃ¡ **automatizada** en el pipeline ETL principal. El pipeline detecta automÃ¡ticamente si existe el CSV del Master Table y lo carga en la base de datos.

---

## ğŸ”„ Flujo Automatizado

### 1. GeneraciÃ³n del Master Table (Manual)

El Master Table se genera ejecutando:

```bash
python scripts/merge_datasets.py
```

**Output**: `data/processed/barcelona_housing_master_table.csv`

**Dependencias**:
- `data/raw/official_prices_2015_2024.csv`
- `data/raw/socioeconomics_renta_2015_2023.csv`
- `data/raw/barrio_structural_attributes.csv`
- `data/raw/advanced_attributes.csv`

### 2. Pipeline ETL (AutomÃ¡tico)

Cuando se ejecuta el pipeline ETL:

```bash
python scripts/process_and_load.py
# o
python -m src.etl.pipeline
```

**El pipeline ahora**:
1. âœ… Carga todas las tablas tradicionales (`fact_precios`, `fact_renta`, etc.)
2. âœ… **Verifica automÃ¡ticamente** si existe `barcelona_housing_master_table.csv`
3. âœ… **Carga automÃ¡ticamente** el Master Table si existe
4. âœ… Registra estadÃ­sticas en `etl_runs`

---

## ğŸ—ï¸ Arquitectura

### MÃ³dulo Reutilizable

**Archivo**: `src/etl/load_master_table.py`

**Funciones principales**:

1. **`create_master_table_schema(conn)`**
   - Crea la tabla `fact_housing_master` y sus Ã­ndices
   - Idempotente (no falla si ya existe)

2. **`load_master_table_from_csv(conn, csv_path, truncate=True)`**
   - Carga datos del CSV a la tabla
   - Valida integridad referencial
   - Carga en chunks para evitar lÃ­mites de SQLite

3. **`load_master_table_if_exists(conn, processed_dir)`**
   - FunciÃ³n de alto nivel para uso en pipeline
   - Retorna `(loaded: bool, count: int)`
   - No falla si el CSV no existe (solo retorna `False`)

### IntegraciÃ³n en Pipeline

**Archivo**: `src/etl/pipeline.py`

**UbicaciÃ³n**: DespuÃ©s de cargar todas las tablas tradicionales, antes de registrar el ETL run.

```python
# Cargar Master Table si existe (opcional)
logger.info("Verificando si existe Master Table para cargar")
master_loaded, master_count = load_master_table_if_exists(
    conn, processed_dir
)
if master_loaded:
    logger.info(
        f"âœ“ Master Table cargado: {master_count:,} registros en fact_housing_master"
    )
    params["fact_housing_master_rows"] = master_count
else:
    logger.debug(
        "Master Table CSV no encontrado. "
        "Ejecute scripts/merge_datasets.py para generarlo."
    )
    params["fact_housing_master_rows"] = 0
```

---

## ğŸ“Š Orden de EjecuciÃ³n

```
1. ExtracciÃ³n (E) - scripts/extract_*.py
   â†“
2. GeneraciÃ³n Master Table (Manual) - scripts/merge_datasets.py
   â†“
3. Pipeline ETL (T+L) - scripts/process_and_load.py
   â”œâ”€ Carga dim_barrios
   â”œâ”€ Carga fact_precios
   â”œâ”€ Carga fact_renta
   â”œâ”€ Carga fact_demografia
   â”œâ”€ Carga fact_oferta_idealista
   â””â”€ âœ… Carga fact_housing_master (automÃ¡tico si existe)
   â†“
4. Registro en etl_runs
```

---

## âœ… Ventajas de la AutomatizaciÃ³n

### 1. **Sin Pasos Manuales Adicionales**
- âœ… El pipeline detecta y carga automÃ¡ticamente
- âœ… No requiere ejecutar `load_master_table_to_db.py` manualmente

### 2. **Robusto y Opcional**
- âœ… No falla si el CSV no existe
- âœ… Solo carga si el archivo estÃ¡ presente
- âœ… Logs claros sobre el estado

### 3. **Trazabilidad**
- âœ… EstadÃ­sticas registradas en `etl_runs`
- âœ… ParÃ¡metro `fact_housing_master_rows` en metadata

### 4. **Reutilizable**
- âœ… MÃ³dulo independiente (`src/etl/load_master_table.py`)
- âœ… Puede usarse en otros contextos
- âœ… Script standalone actualizado para usar el mÃ³dulo

---

## ğŸ”§ Uso Manual (Opcional)

Si necesitas cargar el Master Table manualmente (sin ejecutar todo el pipeline):

```bash
python scripts/load_master_table_to_db.py
```

**Nota**: Este script ahora usa el mismo mÃ³dulo que el pipeline, garantizando consistencia.

---

## ğŸ“ Logs y Trazabilidad

### Durante la EjecuciÃ³n

```
INFO - Verificando si existe Master Table para cargar
INFO - Creando esquema de fact_housing_master
INFO - âœ“ Esquema de fact_housing_master creado exitosamente
INFO - Leyendo Master Table desde data/processed/barcelona_housing_master_table.csv
INFO - Cargando 2,742 registros a fact_housing_master
INFO - âœ“ 2,742 registros cargados exitosamente en fact_housing_master
INFO - âœ“ Master Table cargado: 2,742 registros en fact_housing_master
```

### Si el CSV no existe

```
DEBUG - Master Table CSV no encontrado en data/processed/barcelona_housing_master_table.csv. 
        Omitiendo carga de fact_housing_master.
DEBUG - Master Table CSV no encontrado. Ejecute scripts/merge_datasets.py para generarlo.
```

### En etl_runs

```json
{
  "fact_housing_master_rows": 2742,
  "fact_precios_rows": 6358,
  "fact_renta_rows": 657,
  ...
}
```

---

## âš ï¸ Consideraciones

### 1. **Orden de Dependencias**
- âœ… El Master Table se carga **despuÃ©s** de `dim_barrios`
- âœ… Valida que todos los `barrio_id` existan en `dim_barrios`
- âœ… Filtra automÃ¡ticamente barrios invÃ¡lidos

### 2. **Truncado de Tabla**
- âœ… Por defecto, la tabla se trunca antes de cargar (`truncate=True`)
- âœ… Esto asegura que no haya duplicados
- âš ï¸ Si necesitas preservar datos existentes, modifica el parÃ¡metro

### 3. **GeneraciÃ³n del CSV**
- âš ï¸ El pipeline **NO genera** el CSV automÃ¡ticamente
- âš ï¸ Debes ejecutar `scripts/merge_datasets.py` primero
- âœ… El pipeline solo **carga** el CSV si existe

---

## ğŸ”„ Flujo Completo Recomendado

### OpciÃ³n 1: Pipeline Completo (Recomendado)

```bash
# 1. Extraer datos
python scripts/extract_official_prices.py
python scripts/export_socioeconomics_renta.py
# ... otros extractores

# 2. Generar Master Table
python scripts/merge_datasets.py

# 3. Ejecutar pipeline ETL (carga todo incluyendo Master Table)
python scripts/process_and_load.py
```

### OpciÃ³n 2: Solo Master Table

```bash
# Si solo quieres actualizar el Master Table
python scripts/merge_datasets.py
python scripts/load_master_table_to_db.py
```

---

## ğŸ§ª Testing

Para verificar que la automatizaciÃ³n funciona:

```bash
# 1. Asegurar que el CSV existe
ls data/processed/barcelona_housing_master_table.csv

# 2. Ejecutar pipeline
python scripts/process_and_load.py

# 3. Verificar carga
python scripts/verify_database_state.py | grep fact_housing_master
```

---

## ğŸ“š Referencias

- **MÃ³dulo**: `src/etl/load_master_table.py`
- **Pipeline**: `src/etl/pipeline.py`
- **Script standalone**: `scripts/load_master_table_to_db.py`
- **GeneraciÃ³n Master Table**: `scripts/merge_datasets.py`
- **VerificaciÃ³n**: `scripts/verify_database_state.py`

---

## ğŸ“… Historial

- **2025-12-14**: AutomatizaciÃ³n implementada
  - MÃ³dulo reutilizable creado
  - IntegraciÃ³n en pipeline ETL
  - Script standalone actualizado
  - DocumentaciÃ³n creada

