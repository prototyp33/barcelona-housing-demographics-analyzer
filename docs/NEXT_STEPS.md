# Pr√≥ximos Pasos - Roadmap de Desarrollo

Este documento detalla los pr√≥ximos pasos recomendados para continuar el desarrollo del proyecto Barcelona Housing Demographics Analyzer.

## ‚úÖ Estado Actual

**Completado**:
- ‚úÖ **Milestone 1: Foundation & Data Infrastructure**
  - Extracci√≥n de datos (E) con mejoras avanzadas
  - Transformaci√≥n (T) con esquema dimensional
  - Carga (L) en SQLite
  - Pipeline ETL completo y funcional

**Base de datos disponible**: `data/processed/database.db` con:
- `dim_barrios`: 73 barrios
- `fact_demografia`: 657 registros (2015-2023)
- `fact_precios`: 59 registros (venta 2015)
- `etl_runs`: Auditor√≠a de ejecuciones

---

## üéØ Pr√≥ximos Pasos Recomendados

### **Paso 1: Documentaci√≥n del Esquema de Base de Datos** (Prioridad Alta)

**Objetivo**: Documentar la estructura completa de la base de datos para facilitar an√°lisis y desarrollo.

**Tareas**:
- [ ] Crear `docs/DATABASE_SCHEMA.md` con:
  - Descripci√≥n detallada de cada tabla
  - Relaciones entre tablas (diagrama ER)
  - Ejemplos de consultas SQL comunes
  - Convenciones de nombres y tipos de datos
- [ ] Agregar diagrama de relaciones (usando Mermaid o similar)
- [ ] Documentar √≠ndices y constraints

**Tiempo estimado**: 2-3 horas

---

### **Paso 2: EDA Inicial - Notebook de Exploraci√≥n** (Prioridad Alta)

**Objetivo**: Completar `notebooks/01-eda-initial.ipynb` con an√°lisis exploratorio de los datos cargados.

**Tareas**:
- [ ] Conectar a la base de datos SQLite
- [ ] An√°lisis descriptivo b√°sico:
  - Resumen estad√≠stico de `fact_demografia`
  - Resumen estad√≠stico de `fact_precios`
  - Distribuci√≥n de barrios y distritos
- [ ] Visualizaciones iniciales:
  - Evoluci√≥n temporal de poblaci√≥n por distrito
  - Distribuci√≥n de precios de venta por barrio
  - Mapa de calor de precios vs poblaci√≥n
- [ ] Identificar datos faltantes y outliers
- [ ] Documentar hallazgos iniciales

**Tiempo estimado**: 4-6 horas

**Ejemplo de c√≥digo inicial**:
```python
import sqlite3
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

conn = sqlite3.connect('../data/processed/database.db')

# Cargar datos
df_demo = pd.read_sql_query("""
    SELECT d.*, b.barrio_nombre, b.distrito_nombre
    FROM fact_demografia d
    JOIN dim_barrios b ON d.barrio_id = b.barrio_id
""", conn)

df_precios = pd.read_sql_query("""
    SELECT p.*, b.barrio_nombre, b.distrito_nombre
    FROM fact_precios p
    JOIN dim_barrios b ON p.barrio_id = b.barrio_id
""", conn)
```

---

### **Paso 3: Funciones de An√°lisis B√°sicas** (Prioridad Media)

**Objetivo**: Implementar funciones √∫tiles en `src/analysis.py` para an√°lisis reutilizables.

**Funciones sugeridas**:
- [ ] `get_demographics_by_district(district_name, year_start, year_end)`
- [ ] `get_housing_prices_by_barrio(barrio_name, year_start, year_end)`
- [ ] `calculate_population_growth(barrio_id, year_start, year_end)`
- [ ] `correlate_demographics_prices(district_name=None)`
- [ ] `get_top_barrios_by_metric(metric, top_n=10, year=None)`
- [ ] `compare_barrios(barrio_ids, metrics=['poblacion_total', 'precio_m2_venta'])`

**Tiempo estimado**: 4-6 horas

---

### **Paso 4: Visualizaciones Interactivas B√°sicas** (Prioridad Media)

**Objetivo**: Crear visualizaciones interactivas usando Plotly o Altair.

**Tareas**:
- [ ] Funci√≥n para gr√°fico de evoluci√≥n temporal (poblaci√≥n/precios)
- [ ] Funci√≥n para mapa de calor de correlaciones
- [ ] Funci√≥n para comparaci√≥n de barrios
- [ ] Guardar visualizaciones en `notebooks/visualizations/`

**Tiempo estimado**: 3-4 horas

---

### **Paso 5: Dashboard Streamlit B√°sico** (Prioridad Baja - Futuro)

**Objetivo**: Crear un dashboard interactivo b√°sico en `src/app.py`.

**Funcionalidades iniciales**:
- [ ] Selector de barrio/distrito
- [ ] Visualizaci√≥n de evoluci√≥n temporal
- [ ] Tabla de datos filtrados
- [ ] M√©tricas resumen (poblaci√≥n, precios)

**Tiempo estimado**: 6-8 horas

---

### **Paso 6: Mejoras al Pipeline ETL** (Prioridad Baja)

**Tareas opcionales**:
- [ ] Agregar validaci√≥n de integridad referencial
- [ ] Implementar incremental loads (solo nuevos datos)
- [ ] Agregar tests unitarios para ETL
- [ ] Optimizar consultas SQL

**Tiempo estimado**: 4-6 horas

---

## üìã Plan de Acci√≥n Inmediato (Esta Semana)

### D√≠a 1-2: Documentaci√≥n
1. Crear `docs/DATABASE_SCHEMA.md`
2. Actualizar README con instrucciones de uso del ETL

### D√≠a 3-4: EDA
1. Completar `notebooks/01-eda-initial.ipynb`
2. Generar visualizaciones iniciales
3. Documentar hallazgos

### D√≠a 5: Funciones de An√°lisis
1. Implementar 3-4 funciones b√°sicas en `analysis.py`
2. Probar funciones con datos reales

---

## üîß Comandos √ötiles para Empezar

### Verificar datos en la base de datos:
```bash
python -c "
import sqlite3
import pandas as pd
conn = sqlite3.connect('data/processed/database.db')
print('Barrios:', pd.read_sql_query('SELECT COUNT(*) FROM dim_barrios', conn).iloc[0,0])
print('Demograf√≠a:', pd.read_sql_query('SELECT COUNT(*) FROM fact_demografia', conn).iloc[0,0])
print('Precios:', pd.read_sql_query('SELECT COUNT(*) FROM fact_precios', conn).iloc[0,0])
"
```

### Regenerar base de datos despu√©s de nueva extracci√≥n:
```bash
# 1. Extraer datos actualizados
python scripts/extract_data.py --sources opendatabcn --year-start 2015 --year-end 2023

# 2. Ejecutar ETL
python scripts/process_and_load.py --raw-dir data/raw --processed-dir data/processed
```

### Explorar datos en Jupyter:
```python
# En notebooks/01-eda-initial.ipynb
import sqlite3
import pandas as pd
import matplotlib.pyplot as plt

conn = sqlite3.connect('../data/processed/database.db')

# Ver estructura
tables = pd.read_sql_query(
    "SELECT name FROM sqlite_master WHERE type='table'", 
    conn
)
print(tables)

# Cargar datos combinados
query = """
SELECT 
    d.anio,
    d.poblacion_total,
    d.poblacion_hombres,
    d.poblacion_mujeres,
    p.precio_m2_venta,
    b.barrio_nombre,
    b.distrito_nombre
FROM fact_demografia d
LEFT JOIN fact_precios p ON d.barrio_id = p.barrio_id AND d.anio = p.anio
JOIN dim_barrios b ON d.barrio_id = b.barrio_id
ORDER BY d.anio, b.barrio_nombre
"""

df = pd.read_sql_query(query, conn)
print(df.head())
print(df.info())
```

---

## üìä M√©tricas de √âxito

Para considerar completado cada paso:

- **Paso 1 (Documentaci√≥n)**: 
  - ‚úÖ Documento completo con ejemplos
  - ‚úÖ Diagrama ER incluido
  
- **Paso 2 (EDA)**:
  - ‚úÖ Notebook ejecutable sin errores
  - ‚úÖ Al menos 5 visualizaciones
  - ‚úÖ Hallazgos documentados
  
- **Paso 3 (Funciones)**:
  - ‚úÖ Al menos 5 funciones implementadas
  - ‚úÖ Funciones documentadas con docstrings
  - ‚úÖ Ejemplos de uso incluidos

---

## üöÄ Siguiente Hito

**Objetivo**: Completar Milestone 2 (Initial Analysis & EDA)

**Fecha objetivo**: 1-2 semanas

**Entregables**:
- Documentaci√≥n del esquema
- Notebook EDA completo
- Funciones de an√°lisis b√°sicas
- Visualizaciones iniciales

---

## üí° Notas

- Priorizar calidad sobre cantidad: mejor tener pocas funciones bien documentadas
- Mantener el c√≥digo DRY (Don't Repeat Yourself)
- Documentar decisiones y hallazgos en los notebooks
- Commits frecuentes con mensajes descriptivos

