# Propuesta de ReorganizaciÃ³n: Estructura del Proyecto

**Fecha**: 2025-12-19  
**Contexto**: Proyecto Python (ETL + AnÃ¡lisis + Dashboard) con mÃºltiples componentes  
**Objetivo**: Estructura escalable, predecible y fÃ¡cil de navegar

---

## ğŸ“Š AnÃ¡lisis de la Estructura Actual

### Stack Identificado
- **Lenguaje**: Python 3.9+
- **Componentes principales**:
  - ETL Pipeline (extracciÃ³n, transformaciÃ³n, carga)
  - AnÃ¡lisis de datos (Jupyter notebooks)
  - Dashboard Streamlit
  - Spike de validaciÃ³n (temporal pero extenso)

### Problemas Identificados

1. **Scripts dispersos**: 
   - `scripts/` tiene 71 archivos (difÃ­cil navegar)
   - `spike-data-validation/scripts/` tiene 33 archivos
   - Sin organizaciÃ³n clara por feature/componente

2. **DocumentaciÃ³n dispersa**:
   - `docs/` tiene 50+ archivos sin estructura clara
   - Mezcla de planning, arquitectura, guÃ­as, reports

3. **Spike como subproyecto**:
   - `spike-data-validation/` es temporal pero tiene estructura completa
   - Puede confundir quÃ© es cÃ³digo "oficial" vs "spike"

4. **Dependencias no claras**:
   - Scripts que importan de `src/` y viceversa
   - Sin documentaciÃ³n de dependencias entre mÃ³dulos

---

## ğŸ¯ Propuesta: Estructura por Feature/Componente

### Principios de DiseÃ±o

1. **SeparaciÃ³n clara**: CÃ³digo de producciÃ³n vs scripts temporales vs spikes
2. **Feature-based**: Agrupar por funcionalidad (Catastro, Portal Dades, etc.)
3. **LÃ­mites explÃ­citos**: Documentar quÃ© mÃ³dulos pueden importar quÃ©
4. **Escalabilidad**: FÃ¡cil aÃ±adir nuevas features sin desorganizar

### Estructura Propuesta

```
barcelona-housing-demographics-analyzer/
â”œâ”€â”€ src/                          # CÃ³digo de producciÃ³n (mÃ³dulos reutilizables)
â”‚   â”œâ”€â”€ extraction/              # Extractores por fuente de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # BaseExtractor (pÃºblico)
â”‚   â”‚   â”œâ”€â”€ catastro/            # Feature: Catastro
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ soap_client.py   # Cliente SOAP oficial
â”‚   â”‚   â”‚   â”œâ”€â”€ oficial_client.py # Cliente consulta masiva
â”‚   â”‚   â”‚   â””â”€â”€ parsers.py       # Parsers XML (pÃºblico)
â”‚   â”‚   â”œâ”€â”€ portaldades/         # Feature: Portal Dades
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ extractor.py
â”‚   â”‚   â””â”€â”€ ...                  # Otras fuentes
â”‚   â”œâ”€â”€ etl/                     # Pipeline ETL
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py          # Orquestador principal
â”‚   â”‚   â”œâ”€â”€ transformations/     # Transformaciones por dominio
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ precios.py
â”‚   â”‚   â”‚   â””â”€â”€ demografia.py
â”‚   â”‚   â””â”€â”€ validators.py        # Validaciones (pÃºblico)
â”‚   â”œâ”€â”€ database/                # Acceso a base de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schema.py            # DefiniciÃ³n de schema
â”‚   â”‚   â””â”€â”€ repository.py       # Repositorios tipados (pÃºblico)
â”‚   â”œâ”€â”€ analysis/                # Funciones analÃ­ticas
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py            # Modelos ML/estadÃ­sticos
â”‚   â””â”€â”€ app/                     # Dashboard Streamlit
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ main.py
â”‚       â””â”€â”€ pages/
â”‚
â”œâ”€â”€ scripts/                     # Scripts ejecutables (CLI tools)
â”‚   â”œâ”€â”€ etl/                     # Scripts ETL por feature
â”‚   â”‚   â”œâ”€â”€ run_full_etl.py
â”‚   â”‚   â””â”€â”€ extract_catastro.py
â”‚   â”œâ”€â”€ analysis/                # Scripts de anÃ¡lisis
â”‚   â”‚   â””â”€â”€ train_models.py
â”‚   â”œâ”€â”€ maintenance/             # Scripts de mantenimiento
â”‚   â”‚   â”œâ”€â”€ validate_data.py
â”‚   â”‚   â””â”€â”€ cleanup.py
â”‚   â””â”€â”€ utils/                   # Utilidades compartidas
â”‚       â””â”€â”€ setup_logging.py
â”‚
â”œâ”€â”€ spikes/                      # Spikes temporales (experimentaciÃ³n)
â”‚   â”œâ”€â”€ data-validation/         # Spike actual
â”‚   â”‚   â”œâ”€â”€ scripts/             # Scripts especÃ­ficos del spike
â”‚   â”‚   â”œâ”€â”€ notebooks/           # Notebooks del spike
â”‚   â”‚   â”œâ”€â”€ data/                # Datos del spike
â”‚   â”‚   â””â”€â”€ docs/                # DocumentaciÃ³n del spike
â”‚   â””â”€â”€ README.md                # GuÃ­a: quÃ© es un spike, cuÃ¡ndo migrar
â”‚
â”œâ”€â”€ notebooks/                   # Notebooks de anÃ¡lisis (producciÃ³n)
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â””â”€â”€ 02_analysis.ipynb
â”‚
â”œâ”€â”€ tests/                       # Tests organizados por feature
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â””â”€â”€ database/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ docs/                        # DocumentaciÃ³n organizada
â”‚   â”œâ”€â”€ architecture/            # Decisiones de arquitectura
â”‚   â”œâ”€â”€ guides/                  # GuÃ­as de uso
â”‚   â”œâ”€â”€ api/                     # DocumentaciÃ³n de APIs
â”‚   â”œâ”€â”€ planning/                # Planning y roadmaps
â”‚   â””â”€â”€ spikes/                  # DocumentaciÃ³n de spikes
â”‚
â”œâ”€â”€ data/                        # Datos (sin cambios)
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â””â”€â”€ README.md                    # Actualizar con estructura oficial
```

---

## ğŸ”„ Plan de MigraciÃ³n Gradual

### Fase 1: Reorganizar Scripts (Impacto Bajo)

**Objetivo**: Agrupar scripts por feature sin romper imports.

**Acciones**:
1. Crear estructura `scripts/etl/`, `scripts/analysis/`, `scripts/maintenance/`
2. Mover scripts relacionados con Catastro a `scripts/etl/catastro/`
3. Mover scripts de anÃ¡lisis/modelos a `scripts/analysis/`
4. Actualizar imports en scripts movidos
5. Documentar nueva estructura en `docs/guides/SCRIPTS_ORGANIZATION.md`

**Scripts a mover**:
- `scripts/extract_*.py` â†’ `scripts/etl/extraction/`
- `scripts/train_*.py` â†’ `scripts/analysis/`
- `scripts/validate_*.py` â†’ `scripts/maintenance/`

**Riesgo**: Bajo (solo scripts ejecutables, no mÃ³dulos importados)

---

### Fase 2: Consolidar CÃ³digo de Catastro (Impacto Medio)

**Objetivo**: Mover cÃ³digo reutilizable de `spike-data-validation/scripts/` a `src/extraction/catastro/`.

**CÃ³digo candidato**:
- `catastro_soap_client.py` â†’ `src/extraction/catastro/soap_client.py`
- `catastro_oficial_client.py` â†’ `src/extraction/catastro/oficial_client.py`
- `parse_catastro_masivo_output.py` â†’ `src/extraction/catastro/parsers.py`

**Acciones**:
1. Crear `src/extraction/catastro/`
2. Mover clientes y parsers
3. Actualizar imports en scripts del spike
4. Mantener scripts del spike en `spikes/data-validation/scripts/` que importen de `src/`

**Beneficio**: CÃ³digo reutilizable disponible para producciÃ³n

---

### Fase 3: Reorganizar DocumentaciÃ³n (Impacto Bajo)

**Objetivo**: Estructura clara de documentaciÃ³n.

**Acciones**:
1. Crear `docs/architecture/`, `docs/guides/`, `docs/planning/`
2. Mover ADRs a `docs/architecture/adrs/`
3. Mover guÃ­as de uso a `docs/guides/`
4. Mover planning/roadmaps a `docs/planning/`
5. Crear `docs/README.md` con Ã­ndice

**Archivos a mover**:
- `docs/BEST_PRACTICES_*.md` â†’ `docs/guides/`
- `docs/PROJECT_*.md` â†’ `docs/planning/`
- `docs/architecture/*.md` â†’ Ya estÃ¡ bien ubicado

---

### Fase 4: Clarificar Dependencias (Impacto Alto)

**Objetivo**: Documentar y hacer cumplir lÃ­mites de dependencias.

**Reglas propuestas**:

```
src/                    â†’ Puede importar: stdlib, third-party, src/* (sin ciclos)
scripts/                â†’ Puede importar: stdlib, third-party, src/*
spikes/*/scripts/       â†’ Puede importar: stdlib, third-party, src/* (NO scripts/)
notebooks/              â†’ Puede importar: stdlib, third-party, src/*
tests/                  â†’ Puede importar: stdlib, third-party, src/*, tests/fixtures/
```

**Acciones**:
1. Crear `docs/architecture/DEPENDENCIES.md` con reglas explÃ­citas
2. AÃ±adir validaciÃ³n en CI/CD (opcional, con `import-linter` o similar)
3. Documentar en `CONTRIBUTING.md`

---

## ğŸ“‹ Checklist de ImplementaciÃ³n

### Inmediato (Sin Romper CÃ³digo)
- [ ] Crear `docs/PROJECT_STRUCTURE.md` con estructura oficial
- [ ] Documentar reglas de dependencias en `docs/architecture/DEPENDENCIES.md`
- [ ] Crear `spikes/README.md` explicando quÃ© es un spike y cuÃ¡ndo migrar cÃ³digo

### Corto Plazo (1-2 semanas)
- [ ] Reorganizar `scripts/` por feature (Fase 1)
- [ ] Reorganizar `docs/` por tipo (Fase 3)
- [ ] Actualizar `README.md` con estructura oficial

### Medio Plazo (1 mes)
- [ ] Consolidar cÃ³digo reutilizable de spike a `src/` (Fase 2)
- [ ] Implementar validaciÃ³n de dependencias (Fase 4)
- [ ] Migrar scripts del spike a usar mÃ³dulos de `src/`

---

## ğŸ¯ Beneficios Esperados

1. **NavegaciÃ³n mÃ¡s rÃ¡pida**: Encontrar cÃ³digo por feature en lugar de buscar en 71 archivos
2. **Onboarding mÃ¡s fÃ¡cil**: Estructura predecible para nuevos desarrolladores
3. **Menos acoplamiento**: LÃ­mites claros evitan dependencias cÃ­clicas
4. **ReutilizaciÃ³n**: CÃ³digo del spike disponible para producciÃ³n
5. **Mantenibilidad**: Cambios en una feature no afectan otras

---

## âš ï¸ Consideraciones

### No Mover (Por Ahora)
- `data/` - Estructura actual es clara
- `tests/` - Estructura actual funciona bien
- `notebooks/` - UbicaciÃ³n actual es adecuada

### MigraciÃ³n Gradual
- No hacer grandes movimientos de una vez
- Migrar por feature/componente
- Mantener compatibilidad durante transiciÃ³n
- Documentar cambios en `CHANGELOG.md`

### Spikes
- Mantener `spikes/` separado de producciÃ³n
- Documentar cuÃ¡ndo migrar cÃ³digo de spike a producciÃ³n
- Limpiar spikes completados periÃ³dicamente

---

## ğŸ“š Referencias

- [Python Project Structure Best Practices](https://docs.python-guide.org/writing/structure/)
- [Modularization Guide](https://www.linkedin.com/pulse/modularization-android-projects-kotlin-how-structure-your-levindo-8ipmf)
- [Large Codebase Organization](https://graphite.com/guides/how-to-organize-large-codebases-efficient-reviews)

---

**PrÃ³ximos pasos**: Revisar esta propuesta y decidir quÃ© fases implementar primero.

