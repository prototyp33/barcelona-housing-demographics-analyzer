# üéØ Pr√≥ximos Pasos - Plan de Acci√≥n Concreto

**Fecha de actualizaci√≥n**: 5 de diciembre de 2025  
**Estado actual**: Sprint de Integridad completado ‚úÖ  
**Cobertura actual**: 37% (objetivo: ‚â•80%)

---

## üìä Estado Actual del Proyecto

### ‚úÖ Completado
- ‚úÖ Sprint de Integridad de Datos (PR #99)
- ‚úÖ `fact_precios`: 6,358 registros preservados
- ‚úÖ `dim_barrios`: 73/73 geometr√≠as GeoJSON
- ‚úÖ `fact_demografia`: 0% nulls cr√≠ticos
- ‚úÖ Validaci√≥n de integridad referencial implementada (Issues #67, #81, #82 cerradas)
- ‚úÖ Tests para `cleaners.py` (100% cobertura)
- ‚úÖ Tests para `database_setup.py` (97% cobertura)
- ‚úÖ Tests para `dimensions.py` (80% cobertura)
- ‚úÖ Tests para `pipeline.py` (78% cobertura) - **PR #111 completado**
- ‚úÖ Tests para `demographics.py` (58% cobertura) - **PR #110 completado**
- ‚úÖ Tests para `validators.py` (80% cobertura)

### üìà M√©tricas Actuales
- **Cobertura de tests**: **37%** (mejora desde 24.88%, objetivo: ‚â•80%)
- **M√≥dulos con ‚â•60% cobertura**: 6 m√≥dulos ‚úÖ
- **M√≥dulos pendientes**:
  - `market.py`: 37% ‚ö†Ô∏è (siguiente prioridad)
  - `orchestrator.py`: 4% ‚ö†Ô∏è
  - `opendata.py`: 22% ‚ö†Ô∏è
  - `enrichment.py`: 5% ‚ö†Ô∏è

---

## üöÄ Opciones de Pr√≥ximos Pasos (Priorizadas)

### Opci√≥n 1: Mejorar Cobertura de Tests (Recomendado) üî¥

**Objetivo**: Llevar cobertura de 37% a ‚â•60% (m√≥dulos cr√≠ticos) y ‚â•80% (total)  
**Progreso**: 2 de 4 m√≥dulos cr√≠ticos completados ‚úÖ  
**Tiempo estimado restante**: 1-2 semanas  
**Impacto**: Alta calidad de c√≥digo, menos bugs

#### Paso 1.1: Tests para `demographics.py` ‚úÖ COMPLETADO
**Estado anterior**: 3% cobertura  
**Estado actual**: **58% cobertura** ‚úÖ  
**PR**: #110

**Logros**:
- ‚úÖ 43 tests creados (22 iniciales + 21 adicionales)
- ‚úÖ Tests para `prepare_fact_demografia()` - 8 tests
- ‚úÖ Tests para `enrich_fact_demografia()` - 9 tests
- ‚úÖ Tests para `prepare_demografia_ampliada()` - 7 tests
- ‚úÖ Tests para funciones auxiliares privadas - 19 tests
- ‚úÖ Objetivo de ‚â•60% cumplido

**Comando para verificar**:
```bash
python3 -m pytest tests/test_demographics.py \
  --cov=src.etl.transformations.demographics \
  --cov-report=term-missing
```

---

#### Paso 1.2: Tests para `pipeline.py` ‚úÖ COMPLETADO
**Estado anterior**: 34% cobertura  
**Estado actual**: **78% cobertura** ‚úÖ  
**PR**: #111

**Logros**:
- ‚úÖ 30 tests totales (7 anteriores + 23 nuevos)
- ‚úÖ Tests para funciones auxiliares (100% cobertura):
  - `_find_latest_file()` - 3 tests
  - `_load_metadata()` - 2 tests
  - `_load_manifest()` - 3 tests
  - `_get_latest_file_from_manifest()` - 4 tests
  - `_safe_read_csv()` - 3 tests
- ‚úÖ Tests para `run_etl()` - 8 tests
- ‚úÖ Objetivo de ‚â•60% superado (78%)

**Comando para verificar**:
```bash
python3 -m pytest tests/test_pipeline.py \
  --cov=src.etl.pipeline \
  --cov-report=term-missing
```

---

#### Paso 1.3: Tests para `market.py` (Prioridad Media)
**Estado actual**: 37% cobertura  
**Objetivo**: ‚â•60% cobertura

**√Åreas a cubrir**:
- `prepare_fact_precios()`
- `prepare_renta_barrio()`
- L√≥gica de deduplicaci√≥n
- Validaci√≥n de datos de mercado

**Estimaci√≥n**: 3-4 horas

---

### Opci√≥n 2: Completar Documentaci√≥n üìö

**Objetivo**: Llevar documentaci√≥n de ~50% a ‚â•70%  
**Tiempo estimado**: 1-2 semanas  
**Impacto**: Mejor onboarding, c√≥digo m√°s mantenible

#### Paso 2.1: Documentar funciones principales del ETL
**Archivos prioritarios**:
- `src/etl/pipeline.py`: Documentar flujo completo
- `src/etl/transformations/*`: Docstrings detallados
- `src/extraction/*`: Documentar extractores

**Estructura sugerida**:
```python
def prepare_fact_demografia(...) -> pd.DataFrame:
    """
    Prepara la tabla fact_demografia con datos demogr√°ficos b√°sicos.
    
    Args:
        df_raw: DataFrame con datos brutos de demograf√≠a
        conn: Conexi√≥n a la base de datos
    
    Returns:
        DataFrame con datos preparados para fact_demografia
    
    Raises:
        ValueError: Si faltan columnas requeridas
        sqlite3.Error: Si hay problemas con la base de datos
    
    Example:
        >>> df = prepare_fact_demografia(df_raw, conn)
        >>> df.head()
    """
```

**Estimaci√≥n**: 8-10 horas

---

#### Paso 2.2: Crear gu√≠as de usuario
**Archivos a crear**:
- `docs/USER_GUIDE.md`: Gu√≠a completa para usuarios
- `docs/DEVELOPER_GUIDE.md`: Gu√≠a para desarrolladores
- `docs/API_REFERENCE.md`: Referencia de API

**Estimaci√≥n**: 6-8 horas

---

#### Paso 2.3: Ejemplos pr√°cticos
**Archivos a crear**:
- `docs/examples/extract_data.md`
- `docs/examples/run_etl.md`
- `docs/examples/verify_data.md`
- `docs/examples/query_database.md`

**Estimaci√≥n**: 4-6 horas

---

### Opci√≥n 3: Optimizar Pipeline ETL ‚ö°

**Objetivo**: Mejorar rendimiento y robustez  
**Tiempo estimado**: 1-2 semanas  
**Impacto**: Pipeline m√°s r√°pido y confiable

#### Paso 3.1: Mejorar manejo de errores
**Mejoras**:
- Logging m√°s detallado
- Recovery autom√°tico cuando sea posible
- Mejores mensajes de error
- Retry logic para APIs externas

**Archivos a modificar**:
- `src/etl/pipeline.py`
- `src/extraction/base.py`
- `src/extraction/opendata.py`

**Estimaci√≥n**: 4-6 horas

---

#### Paso 3.2: A√±adir validaciones de calidad
**Validaciones a a√±adir**:
- Validaci√≥n de rangos de valores (precios, poblaci√≥n)
- Validaci√≥n de consistencia temporal
- Validaci√≥n de integridad de datos
- Detecci√≥n de outliers

**Archivos a crear/modificar**:
- `src/etl/validators.py` (expandir)
- Nuevos validadores espec√≠ficos

**Estimaci√≥n**: 6-8 horas

---

#### Paso 3.3: Optimizar consultas SQL
**Mejoras**:
- √çndices adicionales si es necesario
- Optimizar queries complejas
- Batch processing para grandes vol√∫menes

**Estimaci√≥n**: 3-4 horas

---

### Opci√≥n 4: Dashboard Streamlit - Mejoras üé®

**Objetivo**: Dashboard m√°s completo y funcional  
**Tiempo estimado**: 2-3 semanas  
**Impacto**: Mejor experiencia de usuario

#### Paso 4.1: Visualizaciones Geogr√°ficas
**Funcionalidades**:
- Integrar GeoJSON cargado en `dim_barrios`
- Mapas interactivos con Plotly Mapbox
- Choropleth maps por barrio
- Visualizaci√≥n de precios en mapa

**Archivos a modificar**:
- `src/app/main.py`
- Crear `src/app/components/map.py`

**Estimaci√≥n**: 8-10 horas

---

#### Paso 4.2: Filtros Avanzados
**Funcionalidades**:
- Filtro por rango de a√±os
- Filtro por distrito
- Filtro por tipo de operaci√≥n (venta/alquiler)
- B√∫squeda por nombre de barrio

**Estimaci√≥n**: 4-6 horas

---

#### Paso 4.3: Mejoras de UX
**Mejoras**:
- Loading states
- Mejor manejo de errores
- Tooltips informativos
- Mejor dise√±o responsive

**Estimaci√≥n**: 6-8 horas

---

### Opci√≥n 5: Features Nuevas üÜï

**Objetivo**: A√±adir funcionalidades nuevas  
**Tiempo estimado**: Variable  
**Impacto**: Valor a√±adido al proyecto

#### Paso 5.1: Calculadora de Inversi√≥n
**Descripci√≥n**: Calculadora para evaluar inversiones inmobiliarias  
**Archivo**: `docs/features/feature-02-calculator.md`  
**Estimaci√≥n**: 10-12 horas

---

#### Paso 5.2: Sistema de Alertas
**Descripci√≥n**: Alertas cuando cambian precios o demograf√≠a  
**Archivo**: `docs/features/feature-05-alertas.md`  
**Estimaci√≥n**: 8-10 horas

---

#### Paso 5.3: Clustering de Barrios
**Descripci√≥n**: Agrupar barrios por similitud demogr√°fica/precio  
**Archivo**: `docs/features/feature-13-clustering.md`  
**Estimaci√≥n**: 12-15 horas

---

## üìÖ Plan Recomendado (2-3 Semanas)

### Semana 1: Tests y Documentaci√≥n
**D√≠a 1-2**: Tests para `demographics.py`
- Crear `tests/test_demographics.py`
- A√±adir tests para todas las funciones principales
- Objetivo: Llevar cobertura de 3% a ‚â•60%

**D√≠a 3-4**: Tests para `pipeline.py`
- Expandir `tests/test_pipeline.py`
- Tests de integraci√≥n end-to-end
- Objetivo: Llevar cobertura de 34% a ‚â•60%

**D√≠a 5-7**: Documentaci√≥n
- Documentar funciones principales del ETL
- Crear gu√≠as de usuario
- A√±adir ejemplos pr√°cticos

**Resultado esperado**: Cobertura ‚â•60%, Documentaci√≥n ‚â•50%

---

### Semana 2-3: Optimizaci√≥n y Dashboard
**D√≠a 8-10**: Optimizaci√≥n del Pipeline
- Mejorar manejo de errores
- A√±adir validaciones
- Optimizar consultas SQL

**D√≠a 11-14**: Dashboard Streamlit
- Integrar visualizaciones geogr√°ficas
- A√±adir filtros avanzados
- Mejorar UX

---

## üéØ M√©tricas de √âxito

### Cobertura de Tests
- **Actual**: 24.88%
- **Objetivo Sprint 1**: ‚â•60%
- **Objetivo Final**: ‚â•80%

### Documentaci√≥n
- **Actual**: ~50% (estimado)
- **Objetivo Sprint 1**: ‚â•60%
- **Objetivo Final**: ‚â•70%

### Calidad de C√≥digo
- **Tests pasando**: 100% ‚úÖ
- **Linting**: Sin errores ‚úÖ
- **Type hints**: En todas las funciones p√∫blicas ‚ö†Ô∏è

---

## üõ†Ô∏è Comandos √ötiles

### Verificar Estado Actual
```bash
# Verificar estado del sprint
python3 scripts/verify_sprint_status.py

# Ejecutar todos los tests
python3 -m pytest tests/ -v

# Verificar cobertura
python3 -m pytest tests/ --cov=src --cov-report=term-missing

# Ver cobertura de un m√≥dulo espec√≠fico
python3 -m pytest tests/test_demographics.py \
  --cov=src.etl.transformations.demographics \
  --cov-report=term-missing
```

### Desarrollo
```bash
# Crear nueva rama para tests
git checkout -b test/add-demographics-tests

# Ejecutar tests espec√≠ficos
python3 -m pytest tests/test_demographics.py -v

# Ejecutar con coverage
python3 -m pytest tests/ --cov=src --cov-report=html
# Abrir htmlcov/index.html en el navegador
```

---

## üìù Issues a Crear en GitHub

### Alta Prioridad
1. **`test: A√±adir tests para demographics.py`**
   - Tipo: `enhancement`
   - Labels: `testing`, `high-priority`
   - Estimaci√≥n: 4-6 horas
   - Objetivo: Llevar cobertura de 3% a ‚â•60%

2. **`test: A√±adir tests para pipeline.py`**
   - Tipo: `enhancement`
   - Labels: `testing`, `high-priority`
   - Estimaci√≥n: 6-8 horas
   - Objetivo: Tests de integraci√≥n end-to-end

3. **`docs: Completar documentaci√≥n del ETL`**
   - Tipo: `documentation`
   - Labels: `documentation`, `high-priority`
   - Estimaci√≥n: 8-10 horas
   - Objetivo: Documentaci√≥n completa de funciones principales

### Media Prioridad
4. **`refactor: Optimizar pipeline ETL`**
   - Tipo: `enhancement`
   - Labels: `refactoring`, `medium-priority`
   - Estimaci√≥n: 6-8 horas

5. **`feat: Mejorar dashboard Streamlit`**
   - Tipo: `enhancement`
   - Labels: `dashboard`, `medium-priority`
   - Estimaci√≥n: 10-12 horas

---

## üöÄ Recomendaci√≥n Final

**Para empezar ahora mismo**, te recomiendo:

1. **Opci√≥n 1 - Paso 1.1**: Crear tests para `demographics.py`
   - Mayor impacto en calidad de c√≥digo
   - Relativamente r√°pido (4-6 horas)
   - Base s√≥lida para futuras mejoras

2. **Opci√≥n 2 - Paso 2.1**: Documentar funciones principales
   - Mejora mantenibilidad
   - Facilita onboarding
   - Puede hacerse en paralelo con tests

**Comando para empezar**:
```bash
# Crear rama para tests
git checkout -b test/add-demographics-tests

# Crear archivo de tests
touch tests/test_demographics.py

# Empezar a escribir tests
# (ver estructura sugerida arriba)
```

---

## üìö Recursos

- **Documentaci√≥n del Sprint**: `docs/SPRINT_STATUS_DEC_2025.md`
- **Estado del Proyecto**: `docs/PROJECT_STATUS.md`
- **Resumen Ejecutivo**: `docs/PROJECT_STATUS_SUMMARY.md`
- **Plan de Acci√≥n Anterior**: `docs/NEXT_STEPS_ACTION_PLAN.md`
- **Gu√≠a de Contribuci√≥n**: `CONTRIBUTING.md`

---

**√öltima actualizaci√≥n**: 3 de diciembre de 2025

