# Auditor√≠a Completa del Proyecto Barcelona Housing Demographics Analyzer

**Fecha de auditor√≠a:** 2025-12-02  
**Auditor:** Cursor Composer AI  
**Alcance:** C√≥digo fuente completo, documentaci√≥n, issues existentes, commits recientes

---

## üìä Resumen Ejecutivo

### Total de Issues Identificadas: **87**

#### Por Categor√≠a:
- **A. Bugs Cr√≠ticos:** 6
- **B. Bugs Menores:** 8
- **C. Mejoras de Calidad de C√≥digo:** 24
- **D. Refactorings Pendientes:** 5
- **E. Features Incompletas:** 7
- **F. Datos Faltantes:** 5
- **G. Testing:** 12
- **H. Documentaci√≥n:** 8
- **I. DevOps/CI-CD:** 4
- **J. Performance:** 8

#### Por Prioridad:
- üî¥ **Cr√≠tica:** 6 issues
- üü° **Alta:** 18 issues
- üü¢ **Media:** 35 issues
- ‚ö™ **Baja:** 28 issues

### Issues Cr√≠ticas que Bloquean Desarrollo:
1. **C√≥digo duplicado masivo** (`data_extraction.py` vs `extraction/`) - ~2000 l√≠neas duplicadas
2. **SQL Injection potencial** en m√∫ltiples lugares
3. **IncasolSocrataExtractor no registrado** en `__init__.py`
4. **Validaci√≥n de integridad referencial faltante** en ETL
5. **Manejo de errores gen√©rico** en m√∫ltiples m√≥dulos cr√≠ticos
6. **Hardcoding de a√±o 2022** en m√∫ltiples lugares

### Quick Wins (Bajo Esfuerzo, Alto Impacto):
1. Registrar `IncasolSocrataExtractor` en `__init__.py` (15 min)
2. Reemplazar `print()` por logger en `data_extraction.py` (10 min)
3. Eliminar import no utilizado `json` en `enrichment.py` (5 min)
4. A√±adir validaci√≥n de tabla blanca en `data_loader.py` (20 min)
5. Corregir workflow `kpi-update.yml` bare except (10 min)

---

## üìã Issues Detalladas

### A. Bugs Cr√≠ticos (Priority: Critical)

#### A1. C√≥digo Duplicado Masivo: `data_extraction.py` vs `extraction/`
- **id:** A1
- **title:** "üî¥ [BUG] C√≥digo duplicado: `data_extraction.py` legacy duplica funcionalidad de `extraction/`"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `refactoring`, `code-quality`, `technical-debt`
- **affected_files:**
  - `src/data_extraction.py` (2547 l√≠neas)
  - `src/extraction/opendata.py`
  - `src/extraction/idealista.py`
  - `src/extraction/portaldades.py`
- **description:** |
  Existe un m√≥dulo legacy `data_extraction.py` (2547 l√≠neas) que duplica completamente la funcionalidad de los extractores modulares en `src/extraction/`. Esto genera:
  - Confusi√≥n sobre qu√© c√≥digo usar
  - Mantenimiento duplicado
  - Riesgo de inconsistencias entre versiones
  - ~2000 l√≠neas de c√≥digo duplicado
- **current_behavior:** |
  Dos sistemas de extracci√≥n coexisten:
  - Sistema legacy: `src/data_extraction.py` con clases `OpenDataBCNExtractor`, `IdealistaExtractor`, `PortalDadesExtractor`
  - Sistema modular: `src/extraction/` con las mismas clases pero refactorizadas
- **expected_behavior:** |
  Un solo sistema de extracci√≥n modular en `src/extraction/`. El c√≥digo legacy debe eliminarse o marcarse como deprecated con migraci√≥n completa.
- **proposed_solution:** |
  1. Auditar qu√© c√≥digo legacy a√∫n se usa (buscar imports de `data_extraction`)
  2. Migrar todas las referencias a `extraction/`
  3. Eliminar `data_extraction.py` o marcarlo como deprecated con warnings
  4. Actualizar documentaci√≥n y scripts que lo referencien
- **related_issues:** Issue #42, #43
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #1
- **estimated_effort:** 8-12 horas
- **acceptance_criteria:**
  - [ ] No hay imports de `data_extraction` en c√≥digo activo
  - [ ] Todas las referencias migradas a `extraction/`
  - [ ] `data_extraction.py` eliminado o marcado como deprecated
  - [ ] Tests pasan con c√≥digo modular
  - [ ] Documentaci√≥n actualizada
- **source:** `docs/CODE_AUDIT_ISSUES.md` #1

---

#### A2. SQL Injection Potencial en `data_loader.py`
- **id:** A2
- **title:** "üî¥ [BUG] SQL Injection potencial: falta validaci√≥n de tabla blanca en `data_loader.py`"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `security`, `sql-injection`, `streamlit`
- **affected_files:**
  - `src/app/data_loader.py:80`
- **description:** |
  Uso de f-string con nombre de tabla sin validaci√≥n expl√≠cita contra lista blanca. Aunque `table` viene de una lista controlada, es una mala pr√°ctica de seguridad.
- **current_behavior:** |
  ```python
  df = pd.read_sql(f"SELECT MIN(anio) as min_year, MAX(anio) as max_year FROM {table}", conn)
  ```
- **expected_behavior:** |
  Validar que `table` est√© en una lista blanca antes de construir la query.
- **proposed_solution:** |
  ```python
  ALLOWED_TABLES = ["fact_precios", "fact_demografia", "fact_renta"]
  if table not in ALLOWED_TABLES:
      raise ValueError(f"Tabla no permitida: {table}")
  df = pd.read_sql(f"SELECT MIN(anio) as min_year, MAX(anio) as max_year FROM {table}", conn)
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #2
- **estimated_effort:** 20 minutos
- **acceptance_criteria:**
  - [ ] Validaci√≥n de tabla blanca implementada
  - [ ] Test que verifica rechazo de tablas no permitidas
  - [ ] Lista de tablas permitidas documentada
- **source:** `docs/CODE_AUDIT_ISSUES.md` #2

---

#### A3. SQL Injection Potencial en `database_setup.py`
- **id:** A3
- **title:** "üî¥ [BUG] SQL Injection potencial: falta validaci√≥n en `truncate_tables()`"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `security`, `sql-injection`, `database`
- **affected_files:**
  - `src/database_setup.py:214`
- **description:** |
  Similar al anterior, aunque `table` viene de una lista controlada en `truncate_tables()`, falta validaci√≥n expl√≠cita.
- **current_behavior:** |
  ```python
  conn.execute(f"DELETE FROM {table};")
  ```
- **expected_behavior:** |
  Validar expl√≠citamente contra lista blanca antes de ejecutar DELETE.
- **proposed_solution:** |
  ```python
  ALLOWED_TABLES = {"dim_barrios", "fact_precios", "fact_demografia", ...}
  if table not in ALLOWED_TABLES:
      raise ValueError(f"Tabla no permitida para truncado: {table}")
  conn.execute(f"DELETE FROM {table};")
  ```
- **related_issues:** A2
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #3
- **estimated_effort:** 15 minutos
- **acceptance_criteria:**
  - [ ] Validaci√≥n de tabla blanca implementada
  - [ ] Test que verifica rechazo de tablas no permitidas
- **source:** `docs/CODE_AUDIT_ISSUES.md` #3

---

#### A4. IncasolSocrataExtractor No Registrado en `__init__.py`
- **id:** A4
- **title:** "üî¥ [BUG] `IncasolSocrataExtractor` no exportado en `extraction/__init__.py`"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `import-error`, `extraction`
- **affected_files:**
  - `src/extraction/incasol.py`
  - `src/extraction/__init__.py`
- **description:** |
  La clase `IncasolSocrataExtractor` existe en `src/extraction/incasol.py` pero no est√° exportada en `__init__.py`, por lo que no es importable desde `src.extraction`.
- **current_behavior:** |
  ```python
  from src.extraction import IncasolSocrataExtractor  # ‚ùå ImportError
  ```
- **expected_behavior:** |
  ```python
  from src.extraction import IncasolSocrataExtractor  # ‚úÖ Funciona
  ```
- **proposed_solution:** |
  A√±adir en `src/extraction/__init__.py`:
  ```python
  from .incasol import IncasolSocrataExtractor
  __all__ = [
      # ... existing exports ...
      "IncasolSocrataExtractor",
  ]
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #4
- **estimated_effort:** 5 minutos
- **acceptance_criteria:**
  - [ ] `IncasolSocrataExtractor` a√±adido a `__all__`
  - [ ] Import funciona correctamente
  - [ ] Test de import a√±adido
- **source:** `docs/CODE_AUDIT_ISSUES.md` #4

---

#### A5. Uso de `print()` en lugar de Logger
- **id:** A5
- **title:** "üî¥ [BUG] Uso de `print()` en lugar de logger en `data_extraction.py`"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `logging`, `code-quality`
- **affected_files:**
  - `src/data_extraction.py:40`
- **description:** |
  Uso de `print()` para warnings cuando deber√≠a usarse el sistema de logging establecido.
- **current_behavior:** |
  ```python
  print("WARNING: Playwright no est√° instalado...", file=sys.stderr)
  ```
- **expected_behavior:** |
  Usar logger una vez inicializado o inicializar logger antes si es necesario.
- **proposed_solution:** |
  ```python
  logger.warning("Playwright no est√° instalado. El extractor PortalDades requerir√°: pip install playwright && playwright install")
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #5
- **estimated_effort:** 10 minutos
- **acceptance_criteria:**
  - [ ] `print()` reemplazado por logger
  - [ ] Logger inicializado correctamente
- **source:** `docs/CODE_AUDIT_ISSUES.md` #5

---

#### A6. Falta Validaci√≥n de Integridad Referencial en ETL
- **id:** A6
- **title:** "üî¥ [BUG] Falta validaci√≥n de integridad referencial antes de insertar en fact tables"
- **category:** A
- **priority:** critical
- **labels:** `bug`, `database`, `etl`, `data-integrity`
- **affected_files:**
  - `src/etl/pipeline.py`
  - `src/etl/transformations/market.py`
  - `src/etl/transformations/demographics.py`
- **description:** |
  El ETL carga datos en tablas con foreign keys pero no valida expl√≠citamente que todos los `barrio_id` en fact tables existan en `dim_barrios` antes de insertar.
- **current_behavior:** |
  El ETL inserta directamente en fact tables sin validar referencias. SQLite puede fallar silenciosamente o generar errores de foreign key constraint.
- **expected_behavior:** |
  Validar expl√≠citamente que todos los `barrio_id` existen en `dim_barrios` antes de insertar.
- **proposed_solution:** |
  ```python
  # Antes de cargar fact tables, validar:
  invalid_barrios = fact_precios[~fact_precios['barrio_id'].isin(dim_barrios['barrio_id'])]
  if not invalid_barrios.empty:
      logger.error(f"Barrios inv√°lidos encontrados: {invalid_barrios['barrio_id'].unique()}")
      raise ValueError("Integridad referencial violada")
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #8
- **estimated_effort:** 2-3 horas
- **acceptance_criteria:**
  - [ ] Validaci√≥n implementada para todas las fact tables
  - [ ] Logging claro cuando se detectan violaciones
  - [ ] Tests que verifican rechazo de datos inv√°lidos
- **source:** `docs/CODE_AUDIT_ISSUES.md` #8

---

### B. Bugs Menores (Priority: Medium-High)

#### B1. Hardcoding de A√±o 2022 en M√∫ltiples Lugares
- **id:** B1
- **title:** "üü° [BUG] Hardcoding de a√±o 2022 en funciones de `data_loader.py` y `main.py`"
- **category:** B
- **priority:** high
- **labels:** `bug`, `hardcoding`, `streamlit`, `data-quality`
- **affected_files:**
  - `src/app/data_loader.py` (m√∫ltiples funciones)
  - `src/app/main.py:75-88`
- **description:** |
  Los datos de renta ahora est√°n disponibles para 2015-2023, pero el c√≥digo sigue asumiendo solo 2022.
- **current_behavior:** |
  - `load_renta(year: int = 2022)` - hardcodea 2022 como default
  - `load_affordability_data()` - hardcodea `WHERE anio = 2022`
  - `load_temporal_comparison()` - hardcodea `WHERE anio = 2022`
  - UI muestra "Mostrando datos disponibles para **2022**"
- **expected_behavior:** |
  Usar a√±os disponibles din√°micamente desde la base de datos.
- **proposed_solution:** |
  1. Consultar a√±os disponibles din√°micamente desde `load_available_years()`
  2. Actualizar funciones para usar a√±o pasado como par√°metro
  3. Habilitar slider si hay m√∫ltiples a√±os disponibles
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #7, #15
- **estimated_effort:** 2-3 horas
- **acceptance_criteria:**
  - [ ] Funciones usan a√±os din√°micos
  - [ ] UI muestra a√±os disponibles correctamente
  - [ ] Slider habilitado cuando hay m√∫ltiples a√±os
- **source:** `docs/CODE_AUDIT_ISSUES.md` #7, #15

---

#### B2. Validaci√≥n Faltante en `prepare_fact_precios` para Pipes Duplicados
- **id:** B2
- **title:** "üü° [BUG] `prepare_fact_precios` detecta pipes duplicados pero no los corrige autom√°ticamente"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `etl`, `data-quality`
- **affected_files:**
  - `src/etl/transformations/market.py:243-252`
- **description:** |
  La funci√≥n detecta pipes duplicados (`|`) en las columnas `source` y `dataset_id` pero solo loguea un error sin corregir el problema. Aunque existe `_normalize_pipe_tags`, no se aplica autom√°ticamente.
- **current_behavior:** |
  ```python
  if fact["source"].astype(str).str.contains(r"\\|").any():
      logger.error("‚ö†Ô∏è ALERTA: Se detectaron pipes '|' en columna 'source'...")
  # Solo loguea error, no corrige
  ```
- **expected_behavior:** |
  Aplicar `_normalize_pipe_tags` autom√°ticamente cuando se detecten pipes duplicados.
- **proposed_solution:** |
  ```python
  if fact["source"].astype(str).str.contains(r"\\|").any():
      logger.warning("Se detectaron pipes duplicados en 'source'. Normalizando autom√°ticamente.")
      fact["source"] = fact["source"].apply(_normalize_pipe_tags)
  ```
- **related_issues:** Issue #13 (deduplicaci√≥n en fact_precios)
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #4
- **estimated_effort:** 30 minutos
- **acceptance_criteria:**
  - [ ] Normalizaci√≥n autom√°tica implementada
  - [ ] Log level cambiado a WARNING si se corrige autom√°ticamente
  - [ ] Test que verifica correcci√≥n autom√°tica
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #4

---

#### B3. Falta Validaci√≥n de A√±os en Datos de Portal de Dades
- **id:** B3
- **title:** "üü° [BUG] Falta validaci√≥n de a√±os None antes de agrupar en transformaciones"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `etl`, `data-quality`
- **affected_files:**
  - `src/etl/transformations/enrichment.py:112`
  - `src/etl/transformations/utils.py:114-120`
- **description:** |
  `_extract_year_from_temps` puede retornar `None` cuando falla el parsing, pero este valor no siempre se valida antes de agrupar.
- **current_behavior:** |
  Aunque hay `dropna(subset=["anio"])` en algunos lugares, puede haber agrupaciones que fallen si hay None.
- **expected_behavior:** |
  Validar expl√≠citamente que `anio` no sea None antes de agrupar en todos los lugares.
- **proposed_solution:** |
  Asegurar que siempre se valida `dropna(subset=["anio"])` antes de agrupar y a√±adir logging cuando se descarten registros.
- **related_issues:** Issue #15 (mapeo de territorios)
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #7
- **estimated_effort:** 1 hora
- **acceptance_criteria:**
  - [ ] Validaci√≥n de a√±os en todos los lugares de agrupaci√≥n
  - [ ] Logging cuando se descartan registros por a√±o inv√°lido
  - [ ] Test que verifica manejo de a√±os inv√°lidos
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #7

---

#### B4. Falta Validaci√≥n de Estructura de manifest.json
- **id:** B4
- **title:** "üü° [BUG] `_load_manifest` no valida estructura de manifest.json"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `etl`, `data-quality`
- **affected_files:**
  - `src/etl/pipeline.py:45-67`
- **description:** |
  La funci√≥n carga el JSON pero no valida que tenga la estructura esperada (lista de diccionarios con campos espec√≠ficos).
- **current_behavior:** |
  ```python
  manifest = json.load(f)  # ‚ùå No valida estructura
  return manifest
  ```
- **expected_behavior:** |
  Validar que sea una lista y que cada entrada tenga campos m√≠nimos requeridos.
- **proposed_solution:** |
  A√±adir validaci√≥n de tipo (debe ser lista) y campos requeridos en cada entrada, con logging claro cuando el manifest tiene estructura incorrecta.
- **related_issues:** None
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #10
- **estimated_effort:** 1 hora
- **acceptance_criteria:**
  - [ ] Validaci√≥n de tipo implementada
  - [ ] Validaci√≥n de campos requeridos
  - [ ] Logging claro cuando el manifest es inv√°lido
  - [ ] Test que verifica validaci√≥n de manifest inv√°lido
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #10

---

#### B5. Funci√≥n `prepare_idealista_oferta` con L√≥gica Incompleta
- **id:** B5
- **title:** "üü° [BUG] `prepare_idealista_oferta` calcula `num_anuncios_tipologia` pero no lo incluye en resultado"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `etl`, `code-quality`
- **affected_files:**
  - `src/etl/transformations/enrichment.py:277-283`
- **description:** |
  La funci√≥n calcula `num_anuncios_tipologia` pero lo asigna a `_` (descartado), lo que es c√≥digo muerto.
- **current_behavior:** |
  ```python
  if "tipologia" in df.columns:
      _ = (  # ‚ùå Resultado descartado
          df.groupby(group_cols + ["tipologia"])
          .size()
          .reset_index(name="num_anuncios_tipologia")
      )
  ```
- **expected_behavior:** |
  Incluir `num_anuncios_tipologia` en el resultado agregado si es √∫til, o eliminar el c√≥digo si no se necesita.
- **proposed_solution:** |
  Evaluar si es informaci√≥n √∫til. Si s√≠, incluir en el DataFrame agregado (pivot o agregaci√≥n adicional). Si no, eliminar c√≥digo muerto.
- **related_issues:** None
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #11
- **estimated_effort:** 1 hora
- **acceptance_criteria:**
  - [ ] Decisi√≥n documentada sobre si incluir o eliminar
  - [ ] C√≥digo implementado seg√∫n decisi√≥n
  - [ ] Test actualizado
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #11

---

#### B6. Falta Manejo de Errores en `build_geojson`
- **id:** B6
- **title:** "üü° [BUG] `build_geojson` hace `json.loads()` sin manejo de errores"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `streamlit`, `error-handling`
- **affected_files:**
  - `src/app/data_loader.py:446`
- **description:** |
  La funci√≥n hace `json.loads()` sin manejo de errores si el JSON es inv√°lido.
- **current_behavior:** |
  ```python
  geometry = json.loads(row["geometry_json"])  # ‚ùå Puede fallar
  ```
- **expected_behavior:** |
  Manejar `json.JSONDecodeError` y `TypeError` con logging apropiado.
- **proposed_solution:** |
  ```python
  try:
      geometry = json.loads(row["geometry_json"])
  except (json.JSONDecodeError, TypeError) as e:
      logger.warning(f"GeoJSON inv√°lido para barrio {row['barrio_id']}: {e}")
      continue
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #16
- **estimated_effort:** 20 minutos
- **acceptance_criteria:**
  - [ ] Manejo de errores implementado
  - [ ] Logging apropiado
  - [ ] Test que verifica manejo de JSON inv√°lido
- **source:** `docs/CODE_AUDIT_ISSUES.md` #16

---

#### B7. Falta Validaci√≥n de DataFrame Vac√≠o en M√∫ltiples Funciones
- **id:** B7
- **title:** "üü° [BUG] M√∫ltiples funciones no validan DataFrame vac√≠o al inicio"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `data-processing`, `validation`
- **affected_files:**
  - `src/data_processing.py` (m√∫ltiples funciones)
  - `src/etl/transformations/*.py`
- **description:** |
  Muchas funciones asumen que el DataFrame tiene datos pero no validan expl√≠citamente al inicio.
- **current_behavior:** |
  Funciones pueden fallar con errores cr√≠pticos si reciben DataFrame vac√≠o.
- **expected_behavior:** |
  Validar temprano: `if df.empty: return pd.DataFrame()` o `raise ValueError` seg√∫n el caso.
- **proposed_solution:** |
  A√±adir validaci√≥n temprana en todas las funciones de transformaci√≥n y documentar comportamiento cuando DataFrame est√° vac√≠o.
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #17
- **estimated_effort:** 2-3 horas
- **acceptance_criteria:**
  - [ ] Validaci√≥n a√±adida en funciones cr√≠ticas
  - [ ] Comportamiento documentado
  - [ ] Tests que verifican manejo de DataFrames vac√≠os
- **source:** `docs/CODE_AUDIT_ISSUES.md` #17

---

#### B8. Falta Validaci√≥n de Rangos Temporales en ETL
- **id:** B8
- **title:** "üü° [BUG] ETL no valida que a√±os est√©n en rangos esperados"
- **category:** B
- **priority:** medium
- **labels:** `bug`, `etl`, `data-quality`
- **affected_files:**
  - `src/etl/pipeline.py`
  - `src/etl/transformations/*.py`
- **description:** |
  El ETL no valida que los a√±os en los datos est√©n dentro de rangos esperados (ej: no hay a√±os futuros, no hay a√±os antes de 2010).
- **current_behavior:** |
  A√±os inv√°lidos pueden pasar al ETL sin detecci√≥n.
- **expected_behavior:** |
  Validar rangos temporales y loguear warnings cuando se detecten a√±os fuera de rango.
- **proposed_solution:** |
  ```python
  MIN_VALID_YEAR = 2010
  MAX_VALID_YEAR = datetime.now().year + 1
  if (df['anio'] < MIN_VALID_YEAR).any() or (df['anio'] > MAX_VALID_YEAR).any():
      logger.warning(f"A√±os fuera de rango v√°lido detectados")
  ```
- **related_issues:** None
- **related_docs:** `docs/CODE_AUDIT_ISSUES.md` #21
- **estimated_effort:** 1 hora
- **acceptance_criteria:**
  - [ ] Validaci√≥n de rangos implementada
  - [ ] Logging cuando se detectan a√±os inv√°lidos
  - [ ] Tests que verifican validaci√≥n
- **source:** `docs/CODE_AUDIT_ISSUES.md` #21

---

### C. Mejoras de Calidad de C√≥digo (Priority: Medium-Low)

#### C1. Manejo de Errores Gen√©rico en `enrichment.py`
- **id:** C1
- **title:** "üü¢ [QUALITY] Manejo de errores gen√©rico: m√∫ltiples `except Exception` en `enrichment.py`"
- **category:** C
- **priority:** medium
- **labels:** `code-quality`, `etl`, `error-handling`
- **affected_files:**
  - `src/etl/transformations/enrichment.py:52, 164`
- **description:** |
  M√∫ltiples bloques `except Exception` capturan excepciones muy amplias sin especificar tipos concretos.
- **current_behavior:** |
  ```python
  except Exception as exc:  # noqa: BLE001
      logger.warning("Error cargando metadatos: %s", exc)
  ```
- **expected_behavior:** |
  Especificar tipos de excepciones concretos y a√±adir `exc_info=True` a logs de errores.
- **proposed_solution:** |
  ```python
  except (FileNotFoundError, pd.errors.ParserError, json.JSONDecodeError) as exc:
      logger.warning("Error cargando metadatos: %s", exc, exc_info=True)
  except Exception as exc:
      logger.error("Error inesperado: %s", exc, exc_info=True)
      raise
  ```
- **related_issues:** None
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #2
- **estimated_effort:** 1-2 horas
- **acceptance_criteria:**
  - [ ] Tipos espec√≠ficos identificados para cada bloque
  - [ ] `except Exception` reemplazado por tipos concretos donde sea posible
  - [ ] `exc_info=True` a√±adido a logs de errores
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #2

---

#### C2. Manejo de Errores Silencioso en `pipeline.py`
- **id:** C2
- **title:** "üü¢ [QUALITY] Manejo de errores silencioso: m√∫ltiples bloques try/except solo loguean warnings"
- **category:** C
- **priority:** medium
- **labels:** `code-quality`, `etl`, `error-handling`
- **affected_files:**
  - `src/etl/pipeline.py` (m√∫ltiples ubicaciones: 252, 310, 363, 394, 410, 421, 438)
- **description:** |
  M√∫ltiples bloques `try/except` solo loguean warnings pero contin√∫an la ejecuci√≥n, incluso cuando algunos errores podr√≠an ser cr√≠ticos.
- **current_behavior:** |
  ```python
  try:
      renta_df = _safe_read_csv(renta_path)
  except Exception as e:
      logger.warning("Error cargando datos de renta: %s", e)
      # Contin√∫a ejecuci√≥n sin datos de renta
  ```
- **expected_behavior:** |
  Clasificar errores en cr√≠ticos vs. opcionales. Errores cr√≠ticos deber√≠an detener el pipeline, opcionales pueden continuar con warning.
- **proposed_solution:** |
  Clasificar cada fuente como cr√≠tica u opcional. Modificar manejo de errores para fuentes cr√≠ticas (raise en lugar de warning). A√±adir flag `--strict` para pipeline que falle en cualquier error.
- **related_issues:** Issue #43
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #6
- **estimated_effort:** 3-4 horas
- **acceptance_criteria:**
  - [ ] Fuentes clasificadas como cr√≠ticas vs. opcionales
  - [ ] Manejo de errores actualizado seg√∫n clasificaci√≥n
  - [ ] `exc_info=True` a√±adido a todos los logs de errores
  - [ ] Documentaci√≥n de qu√© fuentes son cr√≠ticas
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #6

---

#### C3. Import No Utilizado en `enrichment.py`
- **id:** C3
- **title:** "üü¢ [QUALITY] Import no utilizado: `json` marcado como `# noqa: F401`"
- **category:** C
- **priority:** low
- **labels:** `code-quality`, `cleanup`
- **affected_files:**
  - `src/etl/transformations/enrichment.py:38`
- **description:** |
  El m√≥dulo importa `json` pero est√° marcado como no utilizado con comentario "se mantiene por compatibilidad si se usa en futuras extensiones". Esto es c√≥digo muerto.
- **current_behavior:** |
  ```python
  import json  # noqa: F401  # se mantiene por compatibilidad si se usa en futuras extensiones
  ```
- **expected_behavior:** |
  Eliminar el import si realmente no se usa, o moverlo a donde se necesite cuando se implemente la funcionalidad.
- **proposed_solution:** |
  Verificar que `json` no se usa en ninguna parte del m√≥dulo. Eliminar si no se necesita. Si se necesita en el futuro, a√±adirlo cuando se implemente.
- **related_issues:** None
- **related_docs:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #3
- **estimated_effort:** 5 minutos
- **acceptance_criteria:**
  - [ ] Import eliminado o justificado
  - [ ] C√≥digo limpio sin `# noqa` innecesarios
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #3

---

#### C4-C24. Otros Issues de Calidad de C√≥digo
*(Ver `docs/CODE_AUDIT_ISSUES.md` para detalles completos de issues C4-C24)*

- **C4:** Falta Type Hints Completos
- **C5:** Manejo Inconsistente de Valores Nulos
- **C6:** Falta Validaci√≥n de Esquema en `prepare_renta_barrio`
- **C7:** Cache TTL Hardcodeado en `data_loader.py`
- **C8:** Falta Manejo de Conexiones SQLite en Context Managers
- **C9:** F-Strings en SQL Queries (Aunque con Par√°metros)
- **C10:** Falta Validaci√≥n de A√±os Disponibles en UI
- **C11:** Magic Numbers en C√°lculos
- **C12:** Falta Logging de M√©tricas de Calidad de Datos
- **C13:** Inconsistencia en Nombres de Columnas de Renta
- **C14:** Falta Documentaci√≥n de Estrategias de Deduplicaci√≥n
- **C15:** Falta Manejo de Encoding en `_load_portaldades_csv`
- **C16-C24:** Issues menores de calidad (ver `docs/CODE_AUDIT_ISSUES.md`)

---

### D. Refactorings Pendientes (Priority: Medium)

#### D1. Refactor: Eliminar C√≥digo Legacy `data_extraction.py`
- **id:** D1
- **title:** "üü° [REFACTOR] Eliminar c√≥digo legacy `data_extraction.py` despu√©s de migraci√≥n completa"
- **category:** D
- **priority:** medium
- **labels:** `refactoring`, `technical-debt`, `cleanup`
- **related_issues:** A1
- **estimated_effort:** 2-3 horas
- **source:** `docs/CODE_AUDIT_ISSUES.md` #1

---

#### D2-D5. Otros Refactorings
*(Ver `docs/CODE_AUDIT_ISSUES.md` y `docs/GITHUB_ISSUES.md` para detalles)*

- **D2:** Refactor: Modularizaci√≥n de `data_processing.py` ‚Üí `src/etl/transformations/` (Issue #42, #43)
- **D3:** Refactor: Limpiar orquestador Pipeline (Issue #43)
- **D4:** Refactor: Dividir funciones muy largas (>100 l√≠neas)
- **D5:** Refactor: Reducir acoplamiento entre componentes

---

### E. Features Incompletas (Priority: Varies)

#### E1. INEExtractor Incompleto
- **id:** E1
- **title:** "üü° [FEATURE] Completar implementaci√≥n de `INEExtractor`"
- **category:** E
- **priority:** medium
- **labels:** `feature`, `extraction`, `ine`
- **description:** |
  `INEExtractor` sigue en versi√≥n base. No se han automatizado las descargas de precios hist√≥ricos nacionales.
- **related_issues:** Issue #9 (ISSUES_TO_CREATE.md)
- **estimated_effort:** 4-6 horas
- **source:** `docs/PROJECT_STATUS.md` #5, `docs/ISSUES_TO_CREATE.md` #9

---

#### E2-E7. Otras Features Incompletas
*(Ver documentaci√≥n existente)*

- **E2:** Idealista scraping completo (Issue #10)
- **E3:** Sistema de actualizaci√≥n peri√≥dica automatizada (Issue #11)
- **E4:** Paralelizaci√≥n de extracci√≥n (Issue #12)
- **E5:** Dashboard Streamlit completo (Issue #9, #7)
- **E6:** Funciones de an√°lisis b√°sicas (Issue #6)
- **E7:** Case studies por barrios (Issue #8)

---

### F. Datos Faltantes (Priority: High-Medium)

#### F1. fact_oferta_idealista Vac√≠a
- **id:** F1
- **title:** "üî¥ [DATA] `fact_oferta_idealista` est√° completamente vac√≠a (0 registros)"
- **category:** F
- **priority:** high
- **labels:** `data`, `idealista`, `extraction`
- **description:** |
  Tabla existe pero est√° completamente vac√≠a. Requiere ejecutar discovery script y extracci√≥n.
- **related_issues:** Issue #38 (Sprint 1)
- **estimated_effort:** 2-3 horas
- **source:** `docs/DATOS_FALTANTES.md` #1

---

#### F2-F5. Otros Datos Faltantes
*(Ver `docs/DATOS_FALTANTES.md` para detalles)*

- **F2:** Cobertura temporal limitada de `fact_renta` (solo 1 a√±o)
- **F3:** Datos de alquiler incompletos en `fact_precios` (17.4% de registros)
- **F4:** Campos NULL menores en `fact_demografia` (`porc_inmigracion`: 3.0%)
- **F5:** Geometr√≠as faltantes (aunque seg√∫n PROJECT_STATUS.md ya est√°n cargadas)

---

### G. Testing (Priority: High)

#### G1. Tests Marcados como Skip en `test_pipeline.py`
- **id:** G1
- **title:** "üü° [TEST] 5 tests marcados como skip en `test_pipeline.py`"
- **category:** G
- **priority:** high
- **labels:** `testing`, `etl`, `coverage`
- **affected_files:**
  - `tests/test_pipeline.py:117, 141, 179, 209, 249`
- **description:** |
  M√∫ltiples tests est√°n marcados con `@pytest.mark.skip` porque requieren datos con estructura exacta del esquema real.
- **related_issues:** Issue #20, #40, #37
- **estimated_effort:** 4-6 horas
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #5

---

#### G2-G12. Otros Issues de Testing
*(Ver `docs/CODE_AUDIT_ISSUES.md` y `docs/GITHUB_ISSUES.md`)*

- **G2:** Cobertura baja en m√≥dulos cr√≠ticos (~60% estimado)
- **G3:** Tests de integraci√≥n faltantes para pipeline ETL
- **G4:** Falta tests para funciones de `data_processing.py`
- **G5-G12:** Otros issues de testing (ver documentaci√≥n)

---

### H. Documentaci√≥n (Priority: Low-Medium)

#### H1-H8. Issues de Documentaci√≥n
*(Ver `docs/CODE_AUDIT_ISSUES.md` y `docs/NEXT_STEPS.md`)*

- **H1:** Docstrings faltantes en algunas funciones
- **H2:** README incompleto
- **H3:** Documentaci√≥n desactualizada
- **H4:** Ejemplos de uso faltantes
- **H5:** Falta documentaci√≥n de API de funciones p√∫blicas
- **H6:** Falta documentaci√≥n de estrategias de deduplicaci√≥n
- **H7:** Falta documentaci√≥n de rate limits por fuente
- **H8:** Documentaci√≥n de esquema de base de datos incompleta

---

### I. DevOps/CI-CD (Priority: Medium)

#### I1. Workflow dashboard-demo sin Validaci√≥n de Puerto
- **id:** I1
- **title:** "üü¢ [CI-CD] Workflow `dashboard-demo.yml` sin validaci√≥n de puerto"
- **category:** I
- **priority:** low
- **labels:** `ci-cd`, `workflow`, `validation`
- **affected_files:**
  - `.github/workflows/dashboard-demo.yml:10-14, 38`
- **description:** |
  El workflow acepta un puerto como input string pero no valida que est√© en un rango v√°lido (1024-65535).
- **estimated_effort:** 20 minutos
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #8

---

#### I2. Workflow kpi-update con Manejo de Errores Gen√©rico
- **id:** I2
- **title:** "üü¢ [CI-CD] Workflow `kpi-update.yml` usa bare `except:`"
- **category:** I
- **priority:** low
- **labels:** `ci-cd`, `workflow`, `code-quality`
- **affected_files:**
  - `.github/workflows/kpi-update.yml:48`
- **description:** |
  El workflow usa `except:` sin especificar tipo de excepci√≥n, lo que es una mala pr√°ctica.
- **estimated_effort:** 15 minutos
- **source:** `docs/GITHUB_ISSUES_AUDIT_RECIENTE.md` #9

---

#### I3-I4. Otros Issues de DevOps
- **I3:** Falta validaciones de puerto/par√°metros en workflows
- **I4:** Scripts de deployment faltantes

---

### J. Performance (Priority: Low)

#### J1-J8. Issues de Performance
*(Ver `docs/CODE_AUDIT_ISSUES.md`)*

- **J1:** Optimizaci√≥n de queries SQL
- **J2:** Falta compresi√≥n de archivos raw grandes
- **J3:** Falta validaci√≥n de tama√±o de archivos antes de cargar
- **J4-J8:** Otros issues de performance menores

---

## üó∫Ô∏è Roadmap Sugerido

### Sprint 1 (Pr√≥ximas 2 Semanas) - Quick Wins y Bugs Cr√≠ticos

**Objetivo:** Estabilizar base del proyecto y resolver issues cr√≠ticas

#### Semana 1:
1. ‚úÖ **A4:** Registrar `IncasolSocrataExtractor` (15 min)
2. ‚úÖ **A5:** Reemplazar `print()` por logger (10 min)
3. ‚úÖ **A2:** Validaci√≥n SQL injection en `data_loader.py` (20 min)
4. ‚úÖ **A3:** Validaci√≥n SQL injection en `database_setup.py` (15 min)
5. ‚úÖ **I2:** Corregir workflow `kpi-update.yml` (15 min)
6. ‚úÖ **C3:** Eliminar import no utilizado (5 min)
7. ‚úÖ **B2:** Corregir pipes duplicados autom√°ticamente (30 min)
8. ‚úÖ **B6:** Manejo de errores en `build_geojson` (20 min)

**Total estimado:** ~2 horas

#### Semana 2:
1. ‚úÖ **A6:** Validaci√≥n de integridad referencial (2-3 horas)
2. ‚úÖ **B1:** Eliminar hardcoding de a√±o 2022 (2-3 horas)
3. ‚úÖ **B3:** Validaci√≥n de a√±os en Portal de Dades (1 hora)
4. ‚úÖ **B4:** Validaci√≥n de estructura manifest.json (1 hora)
5. ‚úÖ **B7:** Validaci√≥n de DataFrame vac√≠o (2-3 horas)

**Total estimado:** ~8-11 horas

---

### Sprint 2 (Siguientes 2 Semanas) - Refactoring y Testing

**Objetivo:** Mejorar calidad de c√≥digo y cobertura de tests

1. ‚úÖ **A1:** Auditar y eliminar c√≥digo duplicado `data_extraction.py` (8-12 horas)
2. ‚úÖ **C1:** Mejorar manejo de errores en `enrichment.py` (1-2 horas)
3. ‚úÖ **C2:** Clasificar errores cr√≠ticos vs. opcionales en pipeline (3-4 horas)
4. ‚úÖ **G1:** Habilitar tests skipeados en `test_pipeline.py` (4-6 horas)
5. ‚úÖ **B5:** Completar l√≥gica de `prepare_idealista_oferta` (1 hora)
6. ‚úÖ **B8:** Validaci√≥n de rangos temporales (1 hora)

**Total estimado:** ~18-26 horas

---

### Backlog (Resto) - Features y Mejoras

#### Prioridad Alta:
- **F1:** Completar `fact_oferta_idealista` (2-3 horas)
- **F2:** Ampliar cobertura temporal de `fact_renta` (1-2 horas)
- **E1:** Completar `INEExtractor` (4-6 horas)
- **G2-G4:** Mejorar cobertura de tests (8-12 horas)

#### Prioridad Media:
- **E5:** Dashboard Streamlit completo (6-8 horas)
- **E6:** Funciones de an√°lisis b√°sicas (4-6 horas)
- **H1-H8:** Mejorar documentaci√≥n (6-8 horas)
- **C4-C24:** Mejoras de calidad de c√≥digo (10-15 horas)

#### Prioridad Baja:
- **J1-J8:** Optimizaciones de performance (8-12 horas)
- **E2-E4:** Features futuras (12-20 horas)

---

## üìà M√©tricas de Salud del Proyecto

### C√≥digo
- **L√≠neas de c√≥digo:** ~15,000+ (estimado)
- **C√≥digo duplicado:** ~2000 l√≠neas (üî¥ Alto)
- **Complejidad ciclom√°tica:** üü° Media-Alta en algunas funciones
- **% de funciones con docstrings:** ~70% (üü° Medio)
- **% de funciones con type hints:** ~80% (üü¢ Bueno)

### Testing
- **Cobertura de tests:** ~60% (üü° Medio)
- **Tests skipeados:** 5 tests cr√≠ticos
- **Tests de integraci√≥n:** ‚ö†Ô∏è Faltantes para pipeline ETL

### Calidad
- **TODOs/FIXMEs en c√≥digo:** ~20+ (üü° Medio)
- **Bare exceptions:** ~147 instancias (üî¥ Alto)
- **Imports no utilizados:** ~5-10 (üü¢ Bajo)
- **Linter errors:** ‚úÖ Sin errores

### Deuda T√©cnica
- **Estimada:** ~150-200 horas
- **Cr√≠tica:** ~40 horas (bugs cr√≠ticos y c√≥digo duplicado)
- **Importante:** ~60 horas (refactorings y testing)
- **Mejoras:** ~50-100 horas (features y optimizaciones)

---

## üéØ Conclusiones y Recomendaciones

### Prioridades Inmediatas:
1. **Resolver bugs cr√≠ticos** (A1-A6) antes de nuevas features
2. **Eliminar c√≥digo duplicado** para reducir confusi√≥n y mantenimiento
3. **Mejorar manejo de errores** para facilitar debugging
4. **Aumentar cobertura de tests** para prevenir regresiones

### Quick Wins Recomendados:
- Registrar `IncasolSocrataExtractor` (5 min)
- Eliminar import no utilizado (5 min)
- Corregir workflows CI-CD (30 min)
- Validaciones SQL injection (35 min)

**Total Quick Wins:** ~1.5 horas para resolver 4 issues cr√≠ticas

### Riesgos Identificados:
1. **C√≥digo duplicado:** Alto riesgo de inconsistencias
2. **Manejo de errores gen√©rico:** Dificulta debugging
3. **Tests skipeados:** Regresiones pueden pasar desapercibidas
4. **Datos faltantes:** Limita an√°lisis y funcionalidades

### Pr√≥ximos Pasos:
1. Crear GitHub Issues para todas las issues identificadas
2. Priorizar seg√∫n roadmap sugerido
3. Asignar a sprints seg√∫n capacidad del equipo
4. Actualizar este documento cuando se resuelvan issues

---

**√öltima actualizaci√≥n:** 2025-12-02  
**Pr√≥xima revisi√≥n recomendada:** 2025-12-16 (despu√©s de Sprint 1)

